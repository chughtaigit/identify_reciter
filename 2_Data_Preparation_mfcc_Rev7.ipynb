{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Reciter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2_Data_Preparation\n",
    "This notebook prepares the data for training in the following steps:\n",
    "- Quick look at the downloaded data & select 5 reciters from the downloaded data\n",
    "- Select the Sura/Aya for the reciter\n",
    "- Mark the data for training/validation/test such that the same Sura/Aya are used for these\n",
    "- Select the feature(s) to be extracted\n",
    "- Extract the feature(s)\n",
    "- Save the train/val/test data\n",
    "\n",
    "https://machinelearningmastery.com/develop-bidirectional-lstm-sequence-classification-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take care of package imports and variable defnitions & Helper functions before looking at the downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load helpers.py\n",
    "# Cut-paste above line without \"#\" in cell below & execute once to get code in the cell, \n",
    "# and then execute again to load the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helpers.py LOADED!\n"
     ]
    }
   ],
   "source": [
    "# %load helpers.py\n",
    "##################\n",
    "# imports\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import pathlib\n",
    "import xml.etree.ElementTree as ET\n",
    "import zipfile\n",
    "import shutil\n",
    "import librosa\n",
    "import math\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "import audioread\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub.utils import mediainfo\n",
    "\n",
    "# https://towardsdatascience.com/music-genre-classification-with-python-c714d032f0d8\n",
    "# https://levelup.gitconnected.com/audio-data-analysis-using-deep-learning-part-1-7f6e08803f60\n",
    "# https://www.eurasip.org/Proceedings/Eusipco/Eusipco2018/papers/1570434062.pdf\n",
    "\n",
    "##################\n",
    "# Constants\n",
    "debug          = False\n",
    "zip_data_dir   = '../../L5_Capstone/Audio/Quran'\n",
    "zip_file_name  = '000_versebyverse.zip'\n",
    "data_dir       = 'data'\n",
    "audio_data_dir = os.path.join(os.getcwd(), data_dir, \"audio\")\n",
    "quran_meta_xml = os.path.join(os.getcwd(), data_dir, \"quran-data.xml\")\n",
    "SuraIndexMIN   = 1\n",
    "SuraIndexMAX   = 114\n",
    "AyaIndexMIN    = 0\n",
    "AyaIndexMAX    = 6236\n",
    "\n",
    "# Suppress this warning from librosa:\n",
    "# UserWarning: PySoundFile failed. Trying audioread instead.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if debug:\n",
    "    print(\"quran_meta_xml :\", quran_meta_xml)\n",
    "\n",
    "\n",
    "##################\n",
    "# Functions\n",
    "def hello_world():\n",
    "    print(\"Hello world from helpers.py!\")\n",
    "\n",
    "def qsura_ayat_to_labels(suraFrom=None, suraTo=None, ayaFrom=None, ayaTo=None):\n",
    "    \"\"\" Converts either Sura or Aya numbers to labels.\n",
    "\n",
    "       :param suraFrom: An interger for Sura index to start from. Valid numbers are 1 to 114 (default: None)\n",
    "       :type suraFrom: int\n",
    "       :param suraTo: An interger for Sura index to end to. Valid numbers are 1 to 114 (inclusive) (default: None)\n",
    "       :type suraTo: int\n",
    "       :param ayaFrom: An interger for Aya index to start from (default: None)\n",
    "       :type ayaFrom: int\n",
    "       :param ayaTo: An interger for Aya index to end to (inclusive) (default: None)\n",
    "       :type ayaTo: int\n",
    "       :return: A list of labels in the form ['001001', '001002', ...], A list of aya number in quran [0, 2, ... AyaIndexMAX]\n",
    "       :rtype: list, list \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Return lists\n",
    "    labels_list = list()\n",
    "    ayainq = list()\n",
    "\n",
    "    useSura = False\n",
    "    useAya = False\n",
    "    if suraFrom is not None and suraTo is not None:\n",
    "        if suraFrom < SuraIndexMIN or suraFrom > SuraIndexMAX:\n",
    "            print(\"ERROR: {} not between {} and {}\".format('suraFrom', SuraIndexMIN,SuraIndexMAX))\n",
    "            return labels_list, ayainq\n",
    "        if suraTo < SuraIndexMIN or suraTo > SuraIndexMAX:\n",
    "            print(\"ERROR: {} not between {} and {}\".format('suraTo', SuraIndexMIN,SuraIndexMAX))\n",
    "            return labels_list, ayainq\n",
    "        useSura = True\n",
    "    elif ayaFrom is not None and ayaTo is not None:\n",
    "        if ayaFrom < AyaIndexMIN or ayaFrom > AyaIndexMAX:\n",
    "            print(\"ERROR: {} not between {} and {}\".format('ayaFrom', AyaIndexMIN,AyaIndexMAX))\n",
    "            return labels_list, ayainq\n",
    "        if ayaTo < AyaIndexMIN or ayaTo > AyaIndexMAX:\n",
    "            print(\"ERROR: {} not between {} and {}\".format('ayaTo', AyaIndexMIN,AyaIndexMAX))\n",
    "            return labels_list, ayainq\n",
    "        useAya = True\n",
    "\n",
    "    ##################\n",
    "    # qmeta: Quran Meta Data\n",
    "    qmeta_tree = ET.parse(quran_meta_xml)\n",
    "    qmeta_root = qmeta_tree.getroot()\n",
    "    #print(\"qmeta_root :\", qmeta_root)\n",
    "\n",
    "    # As an Element, root has a tag and a dictionary of attributes:\n",
    "    qmeta_root_tag = qmeta_root.tag\n",
    "    qmeta_root_att = qmeta_root.attrib\n",
    "    #print(\"qmeta_root_tag = \" + qmeta_root_tag)\n",
    "    #print(\"qmeta_root_att = \")\n",
    "    #print(qmeta_root_att)\n",
    "\n",
    "    # It also has children nodes over which we can iterate:\n",
    "    for qmeta_suras in qmeta_root:\n",
    "        qmeta_suras_tag = qmeta_suras.tag\n",
    "        #qmeta_suras_att = qmeta_suras.attrib\n",
    "        #print(\"qmeta_suras_tag = \" + qmeta_suras_tag)\n",
    "        #print(\"qmeta_suras_att = \")\n",
    "        #print(qmeta_suras_att)\n",
    "        if qmeta_suras_tag == \"suras\":\n",
    "            for qmeta_sura in qmeta_suras:\n",
    "                qmeta_sura_tag = qmeta_sura.tag\n",
    "                #qmeta_sura_att = qmeta_sura.attrib\n",
    "                #print(\"qmeta_sura_tag = \" + qmeta_sura_tag)\n",
    "                #print(\"qmeta_sura_att = \")\n",
    "                #print(qmeta_sura_att)\n",
    "                if qmeta_sura_tag == \"sura\":\n",
    "                    #print(\"qmeta_sura :\", qmeta_sura)\n",
    "                    qmeta_sura_index = qmeta_sura.attrib.get('index')\n",
    "                    qmeta_sura_ayas = qmeta_sura.attrib.get('ayas')\n",
    "                    qmeta_sura_start = qmeta_sura.attrib.get('start')\n",
    "                    #print(\"qmeta_sura_index :\", qmeta_sura_index)\n",
    "                    #print(\"qmeta_sura_ayas :\", qmeta_sura_ayas)\n",
    "                    #print(\"qmeta_sura_start :\", qmeta_sura_start)\n",
    "\n",
    "                    if useSura:\n",
    "                        if int(qmeta_sura_index) >= suraFrom and int(qmeta_sura_index) <= suraTo:\n",
    "                            #print(\"  MKC: qmeta_sura_index :\", qmeta_sura_index)\n",
    "                            #print(\"  MKC: qmeta_sura_ayas :\", qmeta_sura_ayas)\n",
    "                            #print(\"  MKC: qmeta_sura_start :\", qmeta_sura_start)\n",
    "                            for i in range(1, int(qmeta_sura_ayas)+1):\n",
    "                                labels_list.append(\"{:03d}{:03d}\".format(int(qmeta_sura_index), i))\n",
    "\n",
    "                    if useAya:\n",
    "                        # Get the current sura end ayat\n",
    "                        sura_start = int(qmeta_sura_start)\n",
    "                        sura_end = sura_start + (int(qmeta_sura_ayas) - 1)\n",
    "                        #print(\"sura start -> end: {} -> {}\".format(sura_start, sura_end))\n",
    "                        for i in range(sura_start, sura_end+1):\n",
    "                            if i >= ayaFrom and i <= ayaTo:\n",
    "                                #print(\"  -> \",i)\n",
    "                                ayainq.append(i)\n",
    "                                labels_list.append(\"{:03d}{:03d}\".format(int(qmeta_sura_index), i+1-sura_start))\n",
    "\n",
    "    #print(\"labels_list :\", labels_list)\n",
    "    return labels_list, ayainq\n",
    "\n",
    "\"\"\"\n",
    "# abc\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(suraFrom=113, suraTo=114, ayaFrom=None, ayaTo=None)\n",
    "print(\"expected_labels_list =\", labels_list)\n",
    "print(\"ayainq_list =\", ayainq_list)\n",
    "print()\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(suraFrom=113, suraTo=115, ayaFrom=None, ayaTo=None)\n",
    "print(\"expected_labels_list =\", labels_list)\n",
    "print(\"ayainq_list =\", ayainq_list)\n",
    "print()\n",
    "\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=0, ayaTo=6)\n",
    "print(\"expected_labels_list =\", labels_list)\n",
    "print(\"ayainq_list =\", ayainq_list)\n",
    "print()\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=1, ayaTo=6)\n",
    "print(\"expected_labels_list =\", labels_list)\n",
    "print(\"ayainq_list =\", ayainq_list)\n",
    "print()\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=1, ayaTo=7)\n",
    "print(\"expected_labels_list =\", labels_list)\n",
    "print(\"ayainq_list =\", ayainq_list)\n",
    "print()\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=0, ayaTo=7)\n",
    "print(\"expected_labels_list =\", labels_list)\n",
    "print(\"ayainq_list =\", ayainq_list)\n",
    "print()\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=0, ayaTo=0)\n",
    "print(\"expected_labels_list =\", labels_list)\n",
    "print(\"ayainq_list =\", ayainq_list)\n",
    "print()\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=0, ayaTo=1)\n",
    "print(\"expected_labels_list =\", labels_list)\n",
    "print(\"ayainq_list =\", ayainq_list)\n",
    "print()\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=290, ayaTo=292)\n",
    "print(\"expected_labels_list =\", labels_list)\n",
    "print(\"ayainq_list =\", ayainq_list)\n",
    "print()\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=6228, ayaTo=6236)\n",
    "print(\"expected_labels_list =\", labels_list)\n",
    "print(\"ayainq_list =\", ayainq_list)\n",
    "print()\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=6228, ayaTo=6237)\n",
    "print(\"expected_labels_list =\", labels_list)\n",
    "print(\"ayainq_list =\", ayainq_list)\n",
    "print()\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=-1, ayaTo=6236)\n",
    "print(\"expected_labels_list =\", labels_list)\n",
    "print(\"ayainq_list =\", ayainq_list)\n",
    "print()\n",
    "# Create a dictonary of lookup between labels and aya number in Quran\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=0, ayaTo=6236)\n",
    "lbl_aya_df = pd.DataFrame(list(zip(labels_list, ayainq_list)), \n",
    "               columns=['Label', 'AyaInQuran']) \n",
    "\n",
    "lbl_aya_dict = dict(zip(labels_list, ayainq_list))\n",
    "\n",
    "print()\n",
    "#print(\"labels_list :\", labels_list)\n",
    "# abc\n",
    "\"\"\"\n",
    "# abc\n",
    "\n",
    "def report_stats_zip_data(zip_data_dir=zip_data_dir, zip_file_name=zip_file_name):\n",
    "    \"\"\" Reports statitics for the zipped data\n",
    "\n",
    "       :param zip_data_dir: Directory containing the zipped data\n",
    "       :type zip_data_dir: str\n",
    "       :param zip_file_name: Name of the zip file in the directory\n",
    "       :type zip_file_name: str\n",
    "       :return: A list of directory names in zip_data_dir\n",
    "       :rtype: list \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Return list\n",
    "    dir_names = list()\n",
    "\n",
    "    # Directory names are also names of the reciters\n",
    "    print(\"{:30s} {:10s} {:8s} {:9s}\".format(\"Reciter name\", \"Data Size\", \"Files\", \"MP3 Files\"))\n",
    "    print(\"{:30s} {:10s} {:8s} {:9s}\".format(\"============\", \"=========\", \"=====\", \"=========\"))\n",
    "    for dd in os.listdir(zip_data_dir):\n",
    "        # Each directory has one zip file called 000_versebyverse.zip\n",
    "        dd_zip_file = zip_data_dir + \"/\" + dd + \"/\" + zip_file_name\n",
    "        # Size\n",
    "        dd_size_bytes = os.path.getsize(dd_zip_file)\n",
    "        dd_size_MB = dd_size_bytes / (1024 * 1024)\n",
    "        # Number of files\n",
    "        archive = zipfile.ZipFile(dd_zip_file, 'r')\n",
    "        num_files = len(archive.namelist())\n",
    "        # Mp3 files\n",
    "        mp3_cnt = 0\n",
    "        for ff in archive.namelist():\n",
    "            if ff.endswith('.mp3'):\n",
    "                mp3_cnt += 1\n",
    "\n",
    "        print(\"{:30s} {:6.0f} MB {:6d} {:12d}\".format(dd, dd_size_MB, num_files, mp3_cnt))\n",
    "        dir_names.append(dd)\n",
    "    return dir_names\n",
    "\n",
    "# Directory size (https://stackoverflow.com/questions/1392413/calculating-a-directorys-size-using-python)\n",
    "def get_dir_size(start_path = '.'):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # skip if it is symbolic link\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "def report_stats_audio_data(data_dir=audio_data_dir):\n",
    "    \"\"\" Reports statitics for the audio data\n",
    "\n",
    "       :param data_dir: Directory containing the audio data\n",
    "       :type data_dir: str\n",
    "       :param zip_file_name: Name of the zip file in the directory\n",
    "       :type zip_file_name: str\n",
    "       :return: DataFrame with audio directory details\n",
    "       :rtype: DataFrame \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    column_names = list()\n",
    "    column_names.append('ReciterName')\n",
    "    column_names.append('FileName')\n",
    "    column_names.append('DataSizeKB')\n",
    "    column_names.append('BitRate')\n",
    "    column_names.append('Channels')\n",
    "    column_names.append('Mono/Stereo')\n",
    "    column_names.append('Duration')\n",
    "    column_names.append('FileNoExt')\n",
    "    column_names.append('Sura')\n",
    "    column_names.append('Aya')\n",
    "    column_names.append('AyaInQuran')\n",
    "\n",
    "    sv_reciter   = list()\n",
    "    sv_file_name = list()\n",
    "    sv_data_size = list()\n",
    "    sv_bit_rate  = list()\n",
    "    sv_ch        = list()\n",
    "    sv_ms        = list()\n",
    "    sv_dur       = list()\n",
    "    sv_filenoext = list()\n",
    "    sv_sura      = list()\n",
    "    sv_aya       = list()\n",
    "    sv_ayainq    = list()\n",
    "\n",
    "    # Directory names are also names of the reciters\n",
    "    print(\"{:30s} {:10s} {:4s} {:4s} {:2s} {:6s} {:9s}\".format(\"Reciter name/MP3 File\", \"Data Size\", \"MP3s\", \"kbps\", \"Ch\", \"Mono/S\", \"Duration(sec)\"))\n",
    "    print(\"{:30s} {:10s} {:4s} {:4s} {:2s} {:6s} {:9s}\".format(\"==============================\", \"=========\", \"====\", \"====\", \"==\", \"======\", \"=============\"))\n",
    "    for dd in os.listdir(data_dir):\n",
    "        reciter_dir = os.path.join(data_dir, dd)\n",
    "        # Size\n",
    "        #dd_size_bytes = os.path.getsize(reciter_dir)\n",
    "        dd_size_bytes = get_dir_size(reciter_dir)\n",
    "        dd_size_KB = dd_size_bytes / (1024)\n",
    "        # Number of files\n",
    "        num_files = len(os.listdir(reciter_dir))\n",
    "        # Mp3 files\n",
    "        mp3_cnt = 0\n",
    "        for ff in os.listdir(reciter_dir):\n",
    "            if ff.endswith('.mp3'):\n",
    "                mp3_cnt += 1\n",
    "\n",
    "        print(\"{:30s} {:6.0f} KB {:5d}\".format(dd, dd_size_KB, mp3_cnt))\n",
    "\n",
    "        for ff in os.listdir(reciter_dir):\n",
    "            if not ff.endswith('.mp3'):\n",
    "                continue\n",
    "            mp3_file = os.path.join(reciter_dir, ff)\n",
    "\n",
    "            duration = channel_layout = bit_rate = channels = bit_rate_kbps = -1\n",
    "            try:\n",
    "                # Look at some audio features\n",
    "                y, sr = librosa.load(mp3_file, sr=None)\n",
    "                # Get the length of the audio\n",
    "                duration = librosa.core.get_duration(y=y, sr=sr)\n",
    "                duration = len(y) / sr\n",
    "\n",
    "                # Sample rate\n",
    "                info = mediainfo(mp3_file)\n",
    "                #print(info)\n",
    "                channel_layout = info['channel_layout']\n",
    "                bit_rate = int(info['bit_rate'])\n",
    "                channels = int(info['channels'])\n",
    "                #artist = info['artist']\n",
    "                artist = \"\"\n",
    "                bit_rate_kbps = bit_rate / 1000\n",
    "            \n",
    "            except:\n",
    "                print(\"Couldn't process, skipping: \", mp3_file)\n",
    "\n",
    "            #print(\"{:>30s} {:6.0f} KB {:5d} {:12d} {:5.1f}\".format(ff, dd_size_KB, 0, int(info['sample_rate']), duration))\n",
    "            #with audioread.audio_open(mp3_file) as input_file:\n",
    "            #    sr_native = input_file.samplerate\n",
    "            #    n_channels = input_file.channels\n",
    "            #print(sr_native, n_channels)\n",
    "            #print(\"{:>30s} {:6.0f} KB {:5s} {:4.0f} {:2d} {:6s} {:13.1f}\".format(ff, dd_size_KB, \"\", bit_rate_kbps, channels, channel_layout, duration))\n",
    "\n",
    "            # Size\n",
    "            dd_size_bytes = os.path.getsize(mp3_file)\n",
    "            dd_size_KB = dd_size_bytes / (1024)\n",
    "\n",
    "            sv_reciter.append(dd)\n",
    "            sv_file_name.append(ff)\n",
    "            sv_data_size.append(int(dd_size_KB))\n",
    "            sv_bit_rate.append(int(bit_rate_kbps))\n",
    "            sv_ch.append(channels)\n",
    "            sv_ms.append(channel_layout)\n",
    "            sv_dur.append(duration)\n",
    "            filenoext, sura, aya, ayainq = get_mp3_file_info(ff)\n",
    "            sv_filenoext.append(filenoext)\n",
    "            sv_sura.append(sura)\n",
    "            sv_aya.append(aya)\n",
    "            sv_ayainq.append(ayainq)\n",
    "            #break\n",
    "        #break\n",
    "    \n",
    "    # Create a DataFrame with all the info\n",
    "    df = pd.DataFrame(list(zip(sv_reciter, sv_file_name, sv_data_size, \n",
    "        sv_bit_rate, sv_ch, sv_ms, sv_dur, sv_filenoext, sv_sura, sv_aya, sv_ayainq)), \n",
    "               columns=column_names) \n",
    "\n",
    "    return df\n",
    "\n",
    "lbl_aya_dict = dict()\n",
    "def get_mp3_file_info(file_name):\n",
    "    \"\"\" Get info from MP3 file name\n",
    "\n",
    "       :param file_name: MP3 file name\n",
    "       :type file_name: str\n",
    "       :return: label, sura, aya, ayainquran\n",
    "       :rtype: str \n",
    "\n",
    "    File name should be ######.mp3, e.g. 001004.mp3\n",
    "        SuraAya    = 001004\n",
    "        Sura       = 1\n",
    "        Aya        = 4\n",
    "        AyaInQuran = 3\n",
    "    \"\"\"\n",
    "\n",
    "    # Return items\n",
    "    suraaya   = ''\n",
    "    sura      = -1\n",
    "    aya       = -1\n",
    "    ayainquan = -1\n",
    "\n",
    "    suraaya = os.path.splitext(file_name)[0]\n",
    "    sura = int(suraaya[:3])\n",
    "    aya  = int(suraaya[3:])\n",
    "    ayainquan = int(lbl_aya_dict[suraaya])\n",
    "\n",
    "    return suraaya, sura, aya, ayainquan\n",
    "\n",
    "def audio_data_initialize(dir_name=audio_data_dir):\n",
    "    \"\"\" Initialize audio data directory\n",
    "\n",
    "       :param dir_name: Directory name to initialize\n",
    "       :type dir_name: str\n",
    "       :return: dir_name\n",
    "       :rtype: str \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # If directory exists, delete the directory \n",
    "    if pathlib.Path(dir_name).exists():\n",
    "        print(\"Directory exists, deleting :\", dir_name)\n",
    "        #pathlib.Path(dir_name).rmdir()\n",
    "        shutil.rmtree(dir_name)\n",
    "\n",
    "    # Create the directory\n",
    "    print(\"Creating directory :\", dir_name)\n",
    "    pathlib.Path(dir_name).mkdir()\n",
    "\n",
    "    return dir_name\n",
    "\n",
    "def populate_audio_files(zip_data_dir=zip_data_dir, zip_file_name=zip_file_name, \n",
    "        audio_data_dir=audio_data_dir, reciters=None, suraFrom=None, suraTo=None,\n",
    "        ayaFrom=None, ayaTo=None, checkOnly=False):\n",
    "    \"\"\" Populate audio files for the reciters in the given directory\n",
    "\n",
    "       :param zip_data_dir: Directory containing the zipped data\n",
    "       :type zip_data_dir: str\n",
    "       :param zip_file_name: Name of the zip file in the directory\n",
    "       :type zip_file_name: str\n",
    "       :return: None\n",
    "       :rtype: None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    audio_labels, ayainq_list = qsura_ayat_to_labels(suraFrom=suraFrom, suraTo=suraTo, \n",
    "        ayaFrom=ayaFrom, ayaTo=ayaTo)\n",
    "    #print(\"Audio labels: \", audio_labels)\n",
    "    #print(\"Aya in Quran labels: \", ayainq_list)\n",
    "\n",
    "    for dd in os.listdir(zip_data_dir):\n",
    "        if dd not in reciters:\n",
    "            continue\n",
    "\n",
    "        print(\"Found reciter: \", dd)\n",
    "        # Create the directory\n",
    "        reciter_dir = os.path.join(audio_data_dir, dd)\n",
    "        print(\"Creating directory :\", reciter_dir)\n",
    "        pathlib.Path(reciter_dir).mkdir()\n",
    "\n",
    "        # Each directory has one zip file called 000_versebyverse.zip\n",
    "        dd_zip_file = zip_data_dir + \"/\" + dd + \"/\" + zip_file_name\n",
    "        # Size\n",
    "        dd_size_bytes = os.path.getsize(dd_zip_file)\n",
    "        dd_size_MB = dd_size_bytes / (1024 * 1024)\n",
    "        # Number of files\n",
    "        archive = zipfile.ZipFile(dd_zip_file, 'r')\n",
    "        num_files = len(archive.namelist())\n",
    "        # Mp3 files\n",
    "        mp3_cnt = 0\n",
    "        for ff in archive.namelist():\n",
    "            if ff.endswith('.mp3'):\n",
    "                mp3_cnt += 1\n",
    "\n",
    "        print(\"{:30s} {:6.0f} MB {:6d} {:12d}\".format(dd, dd_size_MB, num_files, mp3_cnt))\n",
    "\n",
    "        num_files_extracted = 0\n",
    "        for lbl in audio_labels:\n",
    "            mp3_file = lbl + \".mp3\"\n",
    "            if mp3_file not in archive.namelist():\n",
    "                print(\"ERROR: Couldn't find file: \", mp3_file)\n",
    "                continue\n",
    "            archive.extract(mp3_file, path=reciter_dir)\n",
    "            num_files_extracted += 1\n",
    "        print(\"{} files extracted\".format(num_files_extracted))\n",
    "    print()\n",
    "\n",
    "    return None\n",
    "\n",
    "# abc\n",
    "\"\"\"\n",
    "reciter_names = report_stats_zip_data(zip_data_dir=zip_data_dir, zip_file_name=zip_file_name)\n",
    "print(\"Reciter name list :\", reciter_names)\n",
    "\"\"\"\n",
    "# abc\n",
    "\n",
    "\"\"\"\n",
    "selected_reciters = ['AbdulBasit', 'AbdullahBasfar']\n",
    "\"\"\"\n",
    "# abc\n",
    "\"\"\"\n",
    "selected_reciters = ['AbdulBasit', 'AbdullahBasfar', 'AbdulSamad', 'AbdurrahmaanAs-Sudais', 'AbuBakrAsh-Shaatree', 'Ajami', 'Alafasy', 'AliJaber', 'FaresAbbad', 'Ghamadi', 'HaniRifai', 'Karim Mansoori-Iran', 'KhalefaAl-Tunaiji', 'MaherAlMuaiqly', 'MinshawyMujawwad', 'MohammadalTablaway', 'MuhammadAyyoub', 'MuhammadJibreel', 'Parhizgar', 'SaoodbinIbraaheemAsh-Shuraym', 'Sudais']\n",
    "audio_data_initialize(dir_name=audio_data_dir)\n",
    "\n",
    "suraFrom = None\n",
    "suraTo = None\n",
    "ayaFrom = 0\n",
    "ayaTo = 1\n",
    "populate_audio_files(zip_data_dir=zip_data_dir, zip_file_name=zip_file_name, \n",
    "        audio_data_dir=audio_data_dir, reciters=selected_reciters, suraFrom=suraFrom, suraTo=suraTo,\n",
    "        ayaFrom=ayaFrom, ayaTo=ayaTo, checkOnly=True)\n",
    "\n",
    "df = report_stats_audio_data(data_dir=audio_data_dir)\n",
    "\n",
    "print(df)\n",
    "\"\"\"\n",
    "\n",
    "def extract_audio_features(self, list_of_audiofiles):\n",
    "\n",
    "    data = np.zeros(\n",
    "        (len(list_of_audiofiles), self.timeseries_length, 33), dtype=np.float64\n",
    "    )\n",
    "    target = []\n",
    "\n",
    "    for i, file in enumerate(list_of_audiofiles):\n",
    "        y, sr = librosa.load(file)\n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            y=y, sr=sr, hop_length=self.hop_length, n_mfcc=13\n",
    "        )\n",
    "        spectral_center = librosa.feature.spectral_centroid(\n",
    "            y=y, sr=sr, hop_length=self.hop_length\n",
    "        )\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=self.hop_length)\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(\n",
    "            y=y, sr=sr, hop_length=self.hop_length\n",
    "        )\n",
    "\n",
    "        splits = re.split(\"[ .]\", file)\n",
    "        genre = re.split(\"[ /]\", splits[1])[3]\n",
    "        target.append(genre)\n",
    "\n",
    "        data[i, :, 0:13] = mfcc.T[0:self.timeseries_length, :]\n",
    "        data[i, :, 13:14] = spectral_center.T[0:self.timeseries_length, :]\n",
    "        data[i, :, 14:26] = chroma.T[0:self.timeseries_length, :]\n",
    "        data[i, :, 26:33] = spectral_contrast.T[0:self.timeseries_length, :]\n",
    "\n",
    "        print(\n",
    "            \"Extracted features audio track %i of %i.\"\n",
    "            % (i + 1, len(list_of_audiofiles))\n",
    "        )\n",
    "\n",
    "    return data, np.expand_dims(np.asarray(target), axis=1)\n",
    "\n",
    "def extract_audio_features(reciter, mp3_file, sr=22050, n_mfcc=13, n_fft=2048, hop_length=512,\n",
    "    pad_duration=None, read_duration=None, features_list=['mfcc', 'zcr', 'spectral_center', \n",
    "    'spectral_rolloff', 'chroma', 'spectral_bandwidth_2', 'spectral_bandwidth_3', \n",
    "    'spectral_bandwidth_4', 'spectral_contrast'], shp_0=None, shp_1=None):\n",
    "\n",
    "    file_name = os.path.join(audio_data_dir, reciter, mp3_file)\n",
    "\n",
    "    columns = data = feature_shapes = new_shp_0 = new_shp_1 = None\n",
    "\n",
    "    try:\n",
    "        y , sr = librosa.load(file_name, sr=sr, duration=read_duration)\n",
    "        orig_duration = len(y) / sr\n",
    "        #print(\"pad_duration = \", pad_duration)\n",
    "        #print(\"read_duration = \", read_duration)\n",
    "        #print(\"orig_duration = \", orig_duration)\n",
    "        # Pad the duration\n",
    "        if pad_duration is not None:\n",
    "            if pad_duration > orig_duration:\n",
    "                new_len_y = pad_duration * sr\n",
    "                y = librosa.util.fix_length(y, new_len_y)\n",
    "            elif pad_duration <= orig_duration:\n",
    "                # Nothing to be done!\n",
    "                pass\n",
    "        duration = len(y) / sr\n",
    "        #print(\"FINAL: duration = \", duration)\n",
    "\n",
    "        # Column names\n",
    "        columns = list()\n",
    "\n",
    "        # Feature shapes\n",
    "        feature_shapes = list()\n",
    "\n",
    "        #print(\"shp_0 :\", shp_0)\n",
    "        #print(\"shp_1 :\", shp_1)\n",
    "        if shp_0 is not None and shp_1 is not None:\n",
    "            if 'spect' in features_list:\n",
    "                #data = np.empty(\n",
    "                #    (shp_0, shp_1), dtype=np.float64\n",
    "                #)\n",
    "                data = np.empty(\n",
    "                    (shp_1, shp_0), dtype=np.float64\n",
    "                )\n",
    "            else:\n",
    "                data = np.zeros(\n",
    "                    (shp_1, shp_0), dtype=np.float64\n",
    "                )\n",
    "            #data = np.empty(\n",
    "            #  (0, shp_0, shp_1)\n",
    "            #)\n",
    "            #print(\"data initialized:\")\n",
    "            #print(type(data))\n",
    "            #print(data.shape)\n",
    "        else:\n",
    "            data = list()\n",
    "            #print(type(data))\n",
    "\n",
    "        # Start index is 0 and gets updated after feature is concatenated to \"data\"\n",
    "        start_idx = 0\n",
    "        if 'mfcc' in features_list:\n",
    "            #spect = librosa.feature.melspectrogram(y=y, sr=sr,n_fft=n_fft, hop_length=hop_length)\n",
    "            mfcc = librosa.feature.mfcc(\n",
    "                y=y, sr=sr, hop_length=hop_length, n_mfcc=n_mfcc, n_fft=n_fft\n",
    "            )\n",
    "            feature_shapes.append(mfcc.shape)\n",
    "            #print(\"mfcc:\")\n",
    "            #print(mfcc.shape)\n",
    "            #print(mfcc.T)\n",
    "            for i in range(1, mfcc.shape[0]+1):\n",
    "                columns.append('mfcc{}'.format(i))\n",
    "            if shp_0 is not None:\n",
    "                #data = np.append(data, [mfcc.T], axis=0)\n",
    "                data[:, start_idx:start_idx+mfcc.shape[0]] = mfcc.T[0:mfcc.shape[1], :]\n",
    "                start_idx += mfcc.shape[0]\n",
    "                #print(\"mfcc start_idx updated to: \", start_idx)\n",
    "        if 'zcr' in features_list:\n",
    "            zcr = librosa.feature.zero_crossing_rate(y)\n",
    "            feature_shapes.append(zcr.shape)\n",
    "            #print(\"zcr:\")\n",
    "            #print(zcr.shape)\n",
    "            #print(zcr.T)\n",
    "            #print(zcr.shape[1])\n",
    "            columns.append('zcr')\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+zcr.shape[0]] = zcr.T[0:zcr.shape[1], :]\n",
    "                start_idx += zcr.shape[0]\n",
    "                #print(\"zcr start_idx updated to: \", start_idx)\n",
    "        if 'spectral_center' in features_list:\n",
    "            spectral_center = librosa.feature.spectral_centroid(\n",
    "                y=y, sr=sr, hop_length=hop_length\n",
    "            )\n",
    "            feature_shapes.append(spectral_center.shape)\n",
    "            #print(\"spectral_center:\")\n",
    "            #print(spectral_center.shape)\n",
    "            columns.append('spectral_center')\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+spectral_center.shape[0]] = spectral_center.T[0:spectral_center.shape[1], :]\n",
    "                start_idx += spectral_center.shape[0]\n",
    "                #print(\"spectral_center start_idx updated to: \", start_idx)\n",
    "        if 'spectral_rolloff' in features_list:\n",
    "            #spectral_rolloff = librosa.feature.spectral_rolloff(y+0.01, sr=sr)[0]\n",
    "            spectral_rolloff = librosa.feature.spectral_rolloff(y+0.01, sr=sr)\n",
    "            feature_shapes.append(spectral_rolloff.shape)\n",
    "            #print(\"spectral_rolloff:\")\n",
    "            #print(spectral_rolloff.shape)\n",
    "            #print(spectral_rolloff)\n",
    "            columns.append('spectral_rolloff')\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+spectral_rolloff.shape[0]] = spectral_rolloff.T[0:spectral_rolloff.shape[1], :]\n",
    "                start_idx += spectral_rolloff.shape[0]\n",
    "                #print(\"spectral_rolloff start_idx updated to: \", start_idx)\n",
    "        if 'chroma' in features_list:\n",
    "            chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=hop_length)\n",
    "            feature_shapes.append(chroma.shape)\n",
    "            #print(\"chroma:\")\n",
    "            #print(chroma.shape)\n",
    "            for i in range(1, chroma.shape[0]+1):\n",
    "                columns.append('chroma{}'.format(i))\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+chroma.shape[0]] = chroma.T[0:chroma.shape[1], :]\n",
    "                start_idx += chroma.shape[0]\n",
    "                #print(\"chroma start_idx updated to: \", start_idx)\n",
    "        if 'spectral_bandwidth_2' in features_list:\n",
    "            spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(y+0.01, sr=sr)\n",
    "            feature_shapes.append(spectral_bandwidth_2.shape)\n",
    "            #print(\"spectral_bandwidth_2:\")\n",
    "            #print(spectral_bandwidth_2.shape)\n",
    "            columns.append('spectral_bandwidth_2')\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+spectral_bandwidth_2.shape[0]] = spectral_bandwidth_2.T[0:spectral_bandwidth_2.shape[1], :]\n",
    "                start_idx += spectral_bandwidth_2.shape[0]\n",
    "                #print(\"spectral_bandwidth_2 start_idx updated to: \", start_idx)\n",
    "        if 'spectral_bandwidth_3' in features_list:\n",
    "            spectral_bandwidth_3 = librosa.feature.spectral_bandwidth(y+0.01, sr=sr, p=3)\n",
    "            feature_shapes.append(spectral_bandwidth_3.shape)\n",
    "            #print(\"spectral_bandwidth_3:\")\n",
    "            #print(spectral_bandwidth_3.shape)\n",
    "            columns.append('spectral_bandwidth_3')\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+spectral_bandwidth_3.shape[0]] = spectral_bandwidth_3.T[0:spectral_bandwidth_3.shape[1], :]\n",
    "                start_idx += spectral_bandwidth_3.shape[0]\n",
    "                #print(\"spectral_bandwidth_3 start_idx updated to: \", start_idx)\n",
    "        if 'spectral_bandwidth_4' in features_list:\n",
    "            spectral_bandwidth_4 = librosa.feature.spectral_bandwidth(y+0.01, sr=sr, p=4)\n",
    "            feature_shapes.append(spectral_bandwidth_4.shape)\n",
    "            #print(\"spectral_bandwidth_4:\")\n",
    "            #print(spectral_bandwidth_4.shape)\n",
    "            columns.append('spectral_bandwidth_4')\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+spectral_bandwidth_4.shape[0]] = spectral_bandwidth_4.T[0:spectral_bandwidth_4.shape[1], :]\n",
    "                start_idx += spectral_bandwidth_4.shape[0]\n",
    "                #print(\"spectral_bandwidth_4 start_idx updated to: \", start_idx)\n",
    "        if 'spectral_contrast' in features_list:\n",
    "            spectral_contrast = librosa.feature.spectral_contrast(\n",
    "                y=y, sr=sr, hop_length=hop_length\n",
    "            )\n",
    "            feature_shapes.append(spectral_contrast.shape)\n",
    "            #print(\"spectral_contrast:\")\n",
    "            #print(spectral_contrast.shape)\n",
    "            #print(spectral_contrast)\n",
    "            #print(spectral_contrast.T)\n",
    "            for i in range(1, spectral_contrast.shape[0]+1):\n",
    "                columns.append('spcontr{}'.format(i))\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+spectral_contrast.shape[0]] = spectral_contrast.T[0:spectral_contrast.shape[1], :]\n",
    "                start_idx += spectral_contrast.shape[0]\n",
    "                #print(\"spectral_contrast start_idx updated to: \", start_idx)\n",
    "        if 'spect' in features_list:\n",
    "            spect = librosa.feature.melspectrogram(y=y, sr=sr,n_fft=n_fft, hop_length=hop_length)\n",
    "            spect = librosa.power_to_db(spect, ref=np.max)\n",
    "            feature_shapes.append(spect.shape)\n",
    "            #print(\"spect:\")\n",
    "            #print(spect.shape)\n",
    "            for i in range(1, spect.shape[0]+1):\n",
    "                columns.append('spect{}'.format(i))\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+spect.shape[0]] = spect.T[0:spect.shape[1], :]\n",
    "                start_idx += spect.shape[0]\n",
    "                #print(\"spect start_idx updated to: \", start_idx)\n",
    "\n",
    "        new_shp_0 = shp_0\n",
    "        new_shp_1 = shp_1\n",
    "        if shp_0 is None:\n",
    "            #print(feature_shapes)\n",
    "            new_shp_0 = 0\n",
    "            for i, shp in enumerate(feature_shapes):\n",
    "                if i == 0:\n",
    "                    prev_shp_1 = shp[1]\n",
    "                else:\n",
    "                    if shp[1] != prev_shp_1:\n",
    "                        print(\"ERROR: shape[1] are different: {} != {}\".format(shp[1], prev_shp_1))\n",
    "                print(\"shp[0] :\", shp[0])\n",
    "                new_shp_0 += shp[0]\n",
    "            new_shp_1 = prev_shp_1\n",
    "            print(\"new_shp_0 :\", new_shp_0)\n",
    "            print(\"new_shp_1 :\", new_shp_1)\n",
    "\n",
    "        #print(\"duration :\", duration)\n",
    "\n",
    "    except:\n",
    "            print(\"Couldn't process, skipping: \", file_name)\n",
    "\n",
    "    return columns, data, feature_shapes, new_shp_0, new_shp_1\n",
    "\n",
    "\n",
    "# abc\n",
    "\"\"\"\n",
    "# Need to match audio lenghts for all files in order to get arrays of same size for the training\n",
    "new_duration = math.ceil(16.770612244897958)\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "#hop_length = 1024\n",
    "\n",
    "# List of features we want to use\n",
    "features_list=['mfcc', 'zcr', 'spectral_center', \n",
    "    'spectral_rolloff', 'chroma', 'spectral_bandwidth_2', 'spectral_bandwidth_3', \n",
    "    'spectral_bandwidth_4', 'spectral_contrast']\n",
    "features_list = list()\n",
    "features_list.append('mfcc')\n",
    "features_list.append('zcr')\n",
    "\n",
    "# Use one MP3 file to get the array sizes of each feature so starting array can be initialized properly\n",
    "reciter = 'Ajami'\n",
    "mp3_file = '001001.mp3'\n",
    "shp_0 = shp_1 = read_duration = None\n",
    "read_duration = 0.1\n",
    "new_duration = None\n",
    "\"\"\"\n",
    "# abc\n",
    "\n",
    "\"\"\"\n",
    "columns, data, feature_shapes = extract_audio_features(reciter, mp3_file, sr=22050, n_mfcc=13, n_fft=n_fft, hop_length=hop_length, \n",
    "    pad_duration=new_duration, read_duration=read_duration, \n",
    "    features_list=features_list, shp_0=shp_0, shp_1=shp_1)\n",
    "print(columns)\n",
    "# Check to make sure all shapes[1] are the same, and add up all shapes[0]\n",
    "print(feature_shapes)\n",
    "shp_0 = 0\n",
    "for i, shp in enumerate(feature_shapes):\n",
    "    if i == 0:\n",
    "        prev_shp_1 = shp[1]\n",
    "    else:\n",
    "        if shp[1] != prev_shp_1:\n",
    "            print(\"ERROR: shape[1] are different: {} != {}\".format(shp[1], prev_shp_1))\n",
    "    print(\"shp[0] :\", shp[0])\n",
    "    shp_0 += shp[0]\n",
    "shp_1 = prev_shp_1\n",
    "print(\"shp_0 :\", shp_0)\n",
    "print(\"shp_1 :\", shp_1)\n",
    "\n",
    "# Initialize the start array\n",
    "X_arr = np.empty((0, shp_1, shp_0))\n",
    "print(\"X_arr initialized: \")\n",
    "print(type(X_arr))\n",
    "print(X_arr.shape)\n",
    "\n",
    "# Start gathering the data\n",
    "columns, data, feature_shapes = extract_audio_features(reciter, mp3_file, sr=22050, n_mfcc=13, n_fft=n_fft, hop_length=hop_length, \n",
    "    pad_duration=new_duration, read_duration=read_duration, \n",
    "    features_list=features_list, shp_0=shp_0, shp_1=shp_1)\n",
    "#print(data)\n",
    "print(type(data))\n",
    "print(data.shape)\n",
    "#X_arr[0, :, :] = [data]\n",
    "X_arr = np.append(X_arr, [data], axis=0)\n",
    "print(\"X_arr :\")\n",
    "print(type(X_arr))\n",
    "print(X_arr.shape)\n",
    "print(X_arr)\n",
    "exit()\n",
    "mp3_file = '001002.mp3'\n",
    "columns, data, feature_shapes = extract_audio_features(reciter, mp3_file, sr=22050, n_mfcc=13, n_fft=n_fft, hop_length=hop_length, \n",
    "    pad_duration=new_duration, read_duration=read_duration, \n",
    "    features_list=features_list, shp_0=shp_0, shp_1=shp_1)\n",
    "\n",
    "X_arr = np.append(X_arr, [data], axis=0)\n",
    "print(type(X_arr))\n",
    "print(X_arr.shape)\n",
    "\n",
    "# Load an audio file and plot it\n",
    "reciter = 'AbdullahBasfar'\n",
    "columns, data, feature_shapes = extract_audio_features(reciter, mp3_file, sr=22050, n_mfcc=13, n_fft=n_fft, hop_length=hop_length, \n",
    "    pad_duration=new_duration, read_duration=read_duration, \n",
    "    features_list=features_list, shp_0=shp_0, shp_1=shp_1)\n",
    "\n",
    "X_arr = np.append(X_arr, [data], axis=0)\n",
    "print(type(X_arr))\n",
    "print(X_arr.shape)\n",
    "\"\"\"\n",
    "# abc\n",
    "# MKC1\n",
    "\n",
    "Train_Suras = Val_Suras = Test_Suras = None\n",
    "# Add test/train/val column in df\n",
    "def assign_set_sura(row):\n",
    "    train = Train_Suras\n",
    "    val   = Val_Suras\n",
    "    test  = Test_Suras\n",
    "    if row.Sura in val:\n",
    "        return \"validation\"\n",
    "    elif row.Sura in test:\n",
    "        return \"test\"\n",
    "    else:\n",
    "        return \"train\"\n",
    "\n",
    "Train_Ayas = Val_Ayas = Test_Ayas = None\n",
    "# Add test/train/val column in df\n",
    "def assign_set_aya(row):\n",
    "    train = Train_Ayas\n",
    "    val   = Val_Ayas\n",
    "    test  = Test_Ayas\n",
    "    if row.AyaInQuran in val:\n",
    "        return \"validation\"\n",
    "    elif row.AyaInQuran in test:\n",
    "        return \"test\"\n",
    "    else:\n",
    "        return \"train\"\n",
    "\n",
    "def assign_set_filename(row):\n",
    "    train = Train_Ayas\n",
    "    val   = Val_Ayas\n",
    "    test  = Test_Ayas\n",
    "    if row.FileName in val:\n",
    "        return \"validation\"\n",
    "    elif row.FileName in test:\n",
    "        return \"test\"\n",
    "    else:\n",
    "        return \"train\"\n",
    "\n",
    "\"\"\"\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=0, ayaTo=6236)\n",
    "lbl_aya_df = pd.DataFrame(list(zip(labels_list, ayainq_list)), \n",
    "               columns=['Label', 'AyaInQuran']) \n",
    "\n",
    "lbl_aya_dict = dict(zip(labels_list, ayainq_list))\n",
    "\n",
    "ff = '001004.mp3'\n",
    "#print(lbl_aya_dict[ff])\n",
    "\n",
    "#filenoext, sura, aya, ayainq = get_mp3_file_info(ff, dict_lkup=lbl_aya_dict)\n",
    "filenoext, sura, aya, ayainq = get_mp3_file_info(ff)\n",
    "print(filenoext, sura, aya, ayainq)\n",
    "\"\"\"\n",
    "\n",
    "def gen_audio_data(df, shp0, shp1):\n",
    "    print(\"shp0 shp1 = \", shp0, shp1)\n",
    "    X_arr = np.empty((0, shp1, shp0))\n",
    "    print(\"X_arr initialized to :\", X_arr.shape)\n",
    "    reciters_arr = np.empty((0, len(list(le.classes_))))\n",
    "    print(\"reciters_arr initialized to :\", reciters_arr.shape)\n",
    "\n",
    "    cnt = 0\n",
    "    for index, row in df.iterrows():\n",
    "        cnt += 1\n",
    "        ReciterName = row['ReciterName']\n",
    "        FileName = row['FileName']\n",
    "        # Get audio features\n",
    "        columns, data, feature_shapes, new_shp_0, new_shp_1 = extract_audio_features(\n",
    "                reciter=ReciterName, mp3_file=FileName, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, \n",
    "                hop_length=hop_length, pad_duration=pad_duration, read_duration=read_duration, \n",
    "                features_list=features_list, shp_0=shp0, shp_1=shp1)\n",
    "        if columns == None and data == None and feature_shapes == None:\n",
    "            # Skips in case of errors\n",
    "            continue\n",
    "\n",
    "        X_arr = np.append(X_arr, [data], axis=0)\n",
    "                            \n",
    "        reciters_list = [0 for i in range(0, len(list(le.classes_)))]\n",
    "        reciters_index = list(le.transform([ReciterName]))[0]\n",
    "        reciters_list[reciters_index] = 1\n",
    "        reciters_arr = np.append(reciters_arr, [reciters_list], axis=0)\n",
    "            \n",
    "        if cnt % 100 == 0:\n",
    "            print(\"Processed \", cnt)\n",
    "        #if cnt == 10:\n",
    "        #    break\n",
    "\n",
    "    return X_arr, reciters_arr\n",
    "\n",
    "def filter_duration(row):\n",
    "    my_df = df_tmp\n",
    "    FileName = row.FileName\n",
    "    #print(\"FileName =\", FileName)\n",
    "    not_found = False\n",
    "    for rec in selected_reciters:\n",
    "        #print(\"  rec =\", rec)\n",
    "        if ((my_df['ReciterName'] == rec) & (my_df['FileName'] == FileName)).any():\n",
    "            pass\n",
    "        else:\n",
    "            not_found = True\n",
    "            #print(\"not_found =\", not_found)\n",
    "            break\n",
    "    \n",
    "    if not_found == True:\n",
    "        return 'NaN'\n",
    "    else:\n",
    "        return 'Yes'\n",
    "\n",
    "\"\"\"\n",
    "# D:\\\\Khurram\\\\Udacity\\\\Udacity_ML_Course\\\\MKC\\\\P3_Capstone\\\\identify_reciter\\\\data\\\\audio\\\\Ajami\\\\033050.mp3\n",
    "ReciterName = 'Ajami'\n",
    "#FileName    = '033050.mp3'\n",
    "FileName    = '033051.mp3'\n",
    "\n",
    "read_duration = pad_duration = 30\n",
    "#read_duration = pad_duration = None\n",
    "shp_0 = shp_1 = None\n",
    "sr = 22050\n",
    "n_fft = 2048\n",
    "n_mfcc = 13\n",
    "hop_length = 1024\n",
    "#features_list = ['spect']\n",
    "features_list = ['mfcc']\n",
    "\n",
    "columns, data, feature_shapes, new_shp_0, new_shp_1 = extract_audio_features(\n",
    "        reciter=ReciterName, mp3_file=FileName, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, \n",
    "        hop_length=hop_length, pad_duration=pad_duration, read_duration=read_duration, \n",
    "        features_list=features_list, shp_0=shp_0, shp_1=shp_1)\n",
    "\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=0, ayaTo=6236)\n",
    "lbl_aya_df = pd.DataFrame(list(zip(labels_list, ayainq_list)), \n",
    "               columns=['Label', 'AyaInQuran']) \n",
    "\n",
    "lbl_aya_dict = dict(zip(labels_list, ayainq_list))\n",
    "\n",
    "audio_data_dir = os.path.join(os.getcwd(), data_dir, \"audiotest\")\n",
    "df = report_stats_audio_data(data_dir=audio_data_dir)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "from pandas import ExcelWriter\n",
    "my_excel_fileA = 'pd_df_1.xlsx'\n",
    "# Read Excel file\n",
    "df = pd.read_excel(my_excel_fileA)\n",
    "\n",
    "#selected_reciters = ['AbdulBasit', 'AbdurrahmaanAs-Sudais', 'Ajami', 'Alafasy', 'FaresAbbad']\n",
    "dfD = df.copy()\n",
    "newcol = 'Common'\n",
    "dfD[newcol] = 'NaN'\n",
    "\n",
    "#print(dfD.head())\n",
    "df_tmp = dfD[dfD['Duration'] >= 30]\n",
    "\n",
    "my_out_file = 'pd_df_2.xlsx'\n",
    "writer = ExcelWriter(my_out_file)\n",
    "df_tmp.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "\n",
    "df_tmp[newcol] = df_tmp.apply(filter_duration, axis=1)\n",
    "df_tmp = df_tmp[df_tmp[newcol] == 'Yes']\n",
    "\n",
    "FileNames = list(df_tmp['FileName'].unique())\n",
    "print(\"len = \", len(FileNames))\n",
    "tot_ayas = len(FileNames)\n",
    "test_val_ayas = math.ceil(0.2 * tot_ayas)\n",
    "print(\"test_val_ayas = \", test_val_ayas)\n",
    "\n",
    "val_start_idx  = tot_ayas - 1 - test_val_ayas\n",
    "test_start_idx = val_start_idx - test_val_ayas\n",
    "print(\"        val_start_idx = \", val_start_idx)\n",
    "print(\"       test_start_idx = \", test_start_idx)\n",
    "Val_Ayas   = FileNames[val_start_idx+1:tot_ayas+1]\n",
    "Test_Ayas  = FileNames[test_start_idx+1:val_start_idx+1]\n",
    "Train_Ayas = FileNames[0:test_start_idx+1]\n",
    "print(\"Val_Ayas = \", Val_Ayas)\n",
    "\n",
    "df_tmp['Set'] = df_tmp.apply(assign_set_filename, axis=1)\n",
    "\n",
    "my_out_file = 'pd_df_3.xlsx'\n",
    "writer = ExcelWriter(my_out_file)\n",
    "df_tmp.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "\"\"\"\n",
    "\n",
    "print(\"helpers.py LOADED!\")\n",
    "# End of helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dir is:  D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# imports\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import pathlib\n",
    "import xml.etree.ElementTree as ET\n",
    "import zipfile\n",
    "import shutil\n",
    "import librosa\n",
    "import math\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "import audioread\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import ExcelWriter\n",
    "from pydub.utils import mediainfo\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Current dir is: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Constants\n",
    "debug          = False\n",
    "zip_data_dir   = '../../L5_Capstone/Audio/Quran'\n",
    "zip_file_name  = '000_versebyverse.zip'\n",
    "data_dir       = 'datamfcc'\n",
    "audio_data_dir = os.path.join(os.getcwd(), data_dir, \"audio\")\n",
    "quran_meta_xml = os.path.join(os.getcwd(), \"Qurandata\", \"quran-data.xml\")\n",
    "SuraIndexMIN   = 1\n",
    "SuraIndexMAX   = 114\n",
    "AyaIndexMIN    = 0\n",
    "AyaIndexMAX    = 6236\n",
    "\n",
    "# Suppress this warning from librosa:\n",
    "# UserWarning: PySoundFile failed. Trying audioread instead.\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE in 0.017 sec\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>AyaInQuran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>114002</td>\n",
       "      <td>6231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6232</th>\n",
       "      <td>114003</td>\n",
       "      <td>6232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6233</th>\n",
       "      <td>114004</td>\n",
       "      <td>6233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6234</th>\n",
       "      <td>114005</td>\n",
       "      <td>6234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6235</th>\n",
       "      <td>114006</td>\n",
       "      <td>6235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label  AyaInQuran\n",
       "6231  114002        6231\n",
       "6232  114003        6232\n",
       "6233  114004        6233\n",
       "6234  114005        6234\n",
       "6235  114006        6235"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a lookup table between Mp3 filename and ayaInQuran\n",
    "t0 = time.time()\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=AyaIndexMIN, \n",
    "                                                ayaTo=AyaIndexMAX)\n",
    "lbl_aya_df = pd.DataFrame(list(zip(labels_list, ayainq_list)), \n",
    "               columns=['Label', 'AyaInQuran']) \n",
    "\n",
    "lbl_aya_dict = dict(zip(labels_list, ayainq_list))\n",
    "print(\"DONE in {:0.3} sec\\n\".format(time.time() - t0))\n",
    "\n",
    "lbl_aya_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reciter name                   Data Size  Files    MP3 Files\n",
      "============                   =========  =====    =========\n",
      "AbdulBasit                        864 MB   6255         6253\n",
      "AbdullahBasfar                    435 MB   6239         6236\n",
      "AbdulSamad                       1643 MB   6240         6238\n",
      "AbdurrahmaanAs-Sudais             584 MB   6351         6349\n",
      "AbuBakrAsh-Shaatree               729 MB   6356         6353\n",
      "Ajami                            1436 MB   6354         6350\n",
      "Alafasy                           825 MB   6352         6350\n",
      "AliJaber                          701 MB   6354         6351\n",
      "FaresAbbad                        594 MB   6357         6353\n",
      "Ghamadi                           426 MB   6351         6349\n",
      "HaniRifai                         702 MB   6239         6237\n",
      "Karim Mansoori-Iran              1015 MB   6352         6348\n",
      "KhalefaAl-Tunaiji                 757 MB   6238         6236\n",
      "MaherAlMuaiqly                    586 MB   6350         6348\n",
      "MinshawyMujawwad                 1650 MB   6351         6349\n",
      "MohammadalTablaway                822 MB   6352         6350\n",
      "MuhammadAyyoub                    891 MB   6353         6351\n",
      "MuhammadJibreel                   724 MB   6352         6350\n",
      "Parhizgar                         572 MB   6242         6240\n",
      "SaoodbinIbraaheemAsh-Shuraym      510 MB   6360         6358\n",
      "DONE in 1.66 sec\n",
      "\n",
      "\n",
      "Downloaded Reciter name list :\n",
      " ['AbdulBasit', 'AbdullahBasfar', 'AbdulSamad', 'AbdurrahmaanAs-Sudais', 'AbuBakrAsh-Shaatree', 'Ajami', 'Alafasy', 'AliJaber', 'FaresAbbad', 'Ghamadi', 'HaniRifai', 'Karim Mansoori-Iran', 'KhalefaAl-Tunaiji', 'MaherAlMuaiqly', 'MinshawyMujawwad', 'MohammadalTablaway', 'MuhammadAyyoub', 'MuhammadJibreel', 'Parhizgar', 'SaoodbinIbraaheemAsh-Shuraym']\n"
     ]
    }
   ],
   "source": [
    "# Report stats on all downloaded data\n",
    "t0 = time.time()\n",
    "reciter_names = report_stats_zip_data(zip_data_dir=zip_data_dir, zip_file_name=zip_file_name)\n",
    "print(\"DONE in {:0.3} sec\\n\".format(time.time() - t0))\n",
    "\n",
    "print(\"\\nDownloaded Reciter name list :\\n\", reciter_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reciter selection\n",
    "The following 5 reciters were selected:\n",
    "- Abdul Basit -> AbdulBasit\n",
    "- Abdurrahmaan As-Sudais -> AbdurrahmaanAs-Sudais\n",
    "- Ahmed Ibn Ali Al Ajamy -> Ajami\n",
    "- Alafasy\n",
    "- Fares Abbad -> Fares Abbad\n",
    "\n",
    "Select 10 small suras. Roughly 60% suras will be used for training, 20% for validation, and 20% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected reciter:  ['AbdulBasit', 'AbdurrahmaanAs-Sudais', 'Ajami', 'Alafasy', 'FaresAbbad']\n",
      "Selected Suras/Ayas: \n",
      "      suraFrom:  None\n",
      "        suraTo:  None\n",
      "       ayaFrom:  0\n",
      "         ayaTo:  300\n",
      " test_val_ayas:  60\n",
      "\n",
      "        val_start_idx =  240\n",
      "       test_start_idx =  180\n",
      "         Train_Ayas # =  181\n",
      "           Val_Ayas # =  60\n",
      "          Test_Ayas # =  60\n",
      "Train+Val+Test_Ayas # =  301\n",
      "\n",
      "SUCCESS: No overlap between Val & Test & Train - OK to continue\n"
     ]
    }
   ],
   "source": [
    "# List of reciters we are interested in\n",
    "selected_reciters = ['AbdulBasit', 'AbdurrahmaanAs-Sudais', 'Ajami', 'Alafasy', 'FaresAbbad']\n",
    "print(\"Selected reciter: \", selected_reciters)\n",
    "\n",
    "# List of Sura/Ayas we are interested in\n",
    "suraFrom = None\n",
    "suraTo   = None\n",
    "ayaFrom  = AyaIndexMIN\n",
    "ayaTo    = 300\n",
    "# Aya: 60% training, 20% val, 20% test\n",
    "test_val_ayas = math.ceil(0.2 * (ayaTo - ayaFrom))\n",
    "print(\"Selected Suras/Ayas: \")\n",
    "print(\"      suraFrom: \", suraFrom)\n",
    "print(\"        suraTo: \", suraTo)\n",
    "print(\"       ayaFrom: \", ayaFrom)\n",
    "print(\"         ayaTo: \", ayaTo)\n",
    "print(\" test_val_ayas: \", test_val_ayas)\n",
    "print()  \n",
    "\n",
    "if suraFrom is not None and suraTo is not None:\n",
    "    # Train/Val/Test Suras\n",
    "    Train_Suras = [105, 106, 107, 108, 111, 113, 114]\n",
    "    Val_Suras   = [104, 110]\n",
    "    Test_Suras  = [109, 112]\n",
    "    # Check for overlap between Val/Test/Train, if any overlap then resolve\n",
    "    intersection_vtr = list(set(Val_Suras).intersection(Test_Suras))\n",
    "    intersection_trt = list(set(Train_Suras).intersection(Test_Suras))\n",
    "    intersection_trv = list(set(Train_Suras).intersection(Val_Suras))\n",
    "\n",
    "else:\n",
    "    # Train/Val/Test Ayas\n",
    "    val_start_idx  = ayaTo - test_val_ayas\n",
    "    test_start_idx = val_start_idx - test_val_ayas\n",
    "    print(\"        val_start_idx = \", val_start_idx)\n",
    "    print(\"       test_start_idx = \", test_start_idx)\n",
    "    #Train_Ayas = [i for i in range(ayaFrom-1, ayaTo)]\n",
    "    #Val_Ayas   = [i for i in range(ayaTo - (ayaTo - (2 * test_val_ayas)), ayaTo - (1 * test_val_ayas))]\n",
    "    #Test_Ayas  = [i for i in range(ayaTo - (ayaTo - (1 * test_val_ayas)), ayaTo)]\n",
    "    Val_Ayas   = [i for i in range(val_start_idx+1, ayaTo+1)]\n",
    "    Test_Ayas  = [i for i in range(test_start_idx+1, val_start_idx+1)]\n",
    "    Train_Ayas = [i for i in range(ayaFrom, test_start_idx+1)]\n",
    "    print(\"         Train_Ayas # = \", len(Train_Ayas))\n",
    "    print(\"           Val_Ayas # = \", len(Val_Ayas))\n",
    "    print(\"          Test_Ayas # = \", len(Test_Ayas))\n",
    "    print(\"Train+Val+Test_Ayas # = \", len(Train_Ayas)+len(Val_Ayas)+len(Test_Ayas))\n",
    "\n",
    "    # Check for overlap between Val/Test/Train, if any overlap then resolve\n",
    "    intersection_vtr = list(set(Val_Ayas).intersection(Test_Ayas))\n",
    "    intersection_trt = list(set(Train_Ayas).intersection(Test_Ayas))\n",
    "    intersection_trv = list(set(Train_Ayas).intersection(Val_Ayas))\n",
    "\n",
    "print()  \n",
    "if len(intersection_vtr) != 0:\n",
    "    print(\"ERROR: Overlap between Val & Test - Please fix!\", intersection_vtr)\n",
    "if len(intersection_trt) != 0:\n",
    "    print(\"ERROR: Overlap between Train & Test - Please fix!\", intersection_trt)\n",
    "if len(intersection_trv) != 0:\n",
    "    print(\"ERROR: Overlap between Train & Val - Please fix!\", intersection_trv)\n",
    "if len(intersection_vtr) == 0 and len(intersection_trt) == 0 and len(intersection_trv) == 0:\n",
    "    print(\"SUCCESS: No overlap between Val & Test & Train - OK to continue\")\n",
    "else:\n",
    "    print(\"ERROR: Overlaps found, please fix before continuing!\")\n",
    "# Todo:\n",
    "# Add number of ayats for each sura to see how ayats are balanced. However true check will be how much audio length\n",
    "# per test/train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory doesn't exist ...\n",
      "Creating directory : datamfcc\n",
      "Creating directory : D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\\datamfcc\\audio\n",
      "Found reciter:  AbdulBasit\n",
      "Creating directory : D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\\datamfcc\\audio\\AbdulBasit\n",
      "AbdulBasit                        864 MB   6255         6253\n",
      "301 files extracted\n",
      "Found reciter:  AbdurrahmaanAs-Sudais\n",
      "Creating directory : D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\\datamfcc\\audio\\AbdurrahmaanAs-Sudais\n",
      "AbdurrahmaanAs-Sudais             584 MB   6351         6349\n",
      "301 files extracted\n",
      "Found reciter:  Ajami\n",
      "Creating directory : D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\\datamfcc\\audio\\Ajami\n",
      "Ajami                            1436 MB   6354         6350\n",
      "301 files extracted\n",
      "Found reciter:  Alafasy\n",
      "Creating directory : D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\\datamfcc\\audio\\Alafasy\n",
      "Alafasy                           825 MB   6352         6350\n",
      "301 files extracted\n",
      "Found reciter:  FaresAbbad\n",
      "Creating directory : D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\\datamfcc\\audio\\FaresAbbad\n",
      "FaresAbbad                        594 MB   6357         6353\n",
      "301 files extracted\n",
      "\n",
      "DONE in 4.32 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not pathlib.Path(data_dir).exists():\n",
    "    print(\"Directory doesn't exist ...\")\n",
    "    audio_data_initialize(dir_name=data_dir)\n",
    "\n",
    "# Start from a clean data directory\n",
    "audio_data_initialize(dir_name=audio_data_dir)\n",
    "\n",
    "# Populate the data directory with MP3 files for the reciters\n",
    "t0 = time.time()\n",
    "populate_audio_files(zip_data_dir=zip_data_dir, zip_file_name=zip_file_name, \n",
    "        audio_data_dir=audio_data_dir, reciters=selected_reciters, suraFrom=suraFrom, suraTo=suraTo,\n",
    "        ayaFrom=ayaFrom, ayaTo=ayaTo)\n",
    "print(\"DONE in {:0.3} sec\\n\".format(time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reciter name/MP3 File          Data Size  MP3s kbps Ch Mono/S Duration(sec)\n",
      "============================== =========  ==== ==== == ====== =============\n",
      "AbdulBasit                      78609 KB   301\n",
      "AbdurrahmaanAs-Sudais           47721 KB   301\n",
      "Ajami                          108051 KB   301\n",
      "Alafasy                         58687 KB   301\n",
      "FaresAbbad                      55796 KB   301\n",
      "DONE in 4.59e+02 sec\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Report stats on all the extracted MP3 files and get the details in a DataFrame\n",
    "t0 = time.time()\n",
    "df = report_stats_audio_data(data_dir=audio_data_dir)\n",
    "print(\"DONE in {:0.3} sec\\n\".format(time.time() - t0))\n",
    "\n",
    "print(\"\\n\\n\\nDONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP IF DONE EARLIER!!!\n",
    "# Save the df \n",
    "from pandas import ExcelWriter\n",
    "my_excel_fileA = os.path.join(data_dir, 'pd_df_1.xlsx')\n",
    "writer = ExcelWriter(my_excel_fileA)\n",
    "df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read info saved earlier to save time\n",
    "my_excel_fileA = os.path.join(data_dir, 'pd_df_1.xlsx')\n",
    "# Read Excel file\n",
    "df = pd.read_excel(my_excel_fileA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReciterName</th>\n",
       "      <th>FileName</th>\n",
       "      <th>DataSizeKB</th>\n",
       "      <th>BitRate</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Mono/Stereo</th>\n",
       "      <th>Duration</th>\n",
       "      <th>FileNoExt</th>\n",
       "      <th>Sura</th>\n",
       "      <th>Aya</th>\n",
       "      <th>AyaInQuran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>001001.mp3</td>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>4.336327</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>001002.mp3</td>\n",
       "      <td>42</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>5.276735</td>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>001003.mp3</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>3.996735</td>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>001004.mp3</td>\n",
       "      <td>36</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>4.519184</td>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>001005.mp3</td>\n",
       "      <td>44</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>5.590204</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ReciterName    FileName  DataSizeKB  BitRate  Channels Mono/Stereo  \\\n",
       "0  AbdulBasit  001001.mp3          34       64         2      stereo   \n",
       "1  AbdulBasit  001002.mp3          42       64         2      stereo   \n",
       "2  AbdulBasit  001003.mp3          32       64         2      stereo   \n",
       "3  AbdulBasit  001004.mp3          36       64         2      stereo   \n",
       "4  AbdulBasit  001005.mp3          44       64         2      stereo   \n",
       "\n",
       "   Duration  FileNoExt  Sura  Aya  AyaInQuran  \n",
       "0  4.336327       1001     1    1           0  \n",
       "1  5.276735       1002     1    2           1  \n",
       "2  3.996735       1003     1    3           2  \n",
       "3  4.519184       1004     1    4           3  \n",
       "4  5.590204       1005     1    5           4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick look at the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1505, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick look at the DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len =  301\n",
      "test_val_ayas =  61\n",
      "        val_start_idx =  239\n",
      "       test_start_idx =  178\n"
     ]
    }
   ],
   "source": [
    "from pandas import ExcelWriter\n",
    "\n",
    "def filter_duration(row):\n",
    "    my_df = df_tmp\n",
    "    FileName = row.FileName\n",
    "    #print(\"FileName =\", FileName)\n",
    "    not_found = False\n",
    "    for rec in selected_reciters:\n",
    "        #print(\"  rec =\", rec)\n",
    "        if ((my_df['ReciterName'] == rec) & (my_df['FileName'] == FileName)).any():\n",
    "            pass\n",
    "        else:\n",
    "            not_found = True\n",
    "            #print(\"not_found =\", not_found)\n",
    "            break\n",
    "    \n",
    "    if not_found == True:\n",
    "        return 'NaN'\n",
    "    else:\n",
    "        return 'Yes'\n",
    "\n",
    "def assign_set_filename(row):\n",
    "    train = Train_Ayas\n",
    "    val   = Val_Ayas\n",
    "    test  = Test_Ayas\n",
    "    if row.FileName in val:\n",
    "        return \"validation\"\n",
    "    elif row.FileName in test:\n",
    "        return \"test\"\n",
    "    else:\n",
    "        return \"train\"\n",
    "\n",
    "#selected_reciters = ['AbdulBasit', 'AbdurrahmaanAs-Sudais', 'Ajami', 'Alafasy', 'FaresAbbad']\n",
    "dfD = df.copy()\n",
    "newcol = 'Common'\n",
    "#dfD[newcol] = 'NaN'\n",
    "dfD[newcol] = 'Yes'\n",
    "\n",
    "#print(dfD.head())\n",
    "#df_tmp = dfD[dfD['Duration'] >= 30]\n",
    "df_tmp = dfD\n",
    "\n",
    "my_out_file = os.path.join(data_dir, 'pd_df_2.xlsx')\n",
    "writer = ExcelWriter(my_out_file)\n",
    "df_tmp.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "\n",
    "#df_tmp[newcol] = df_tmp.apply(filter_duration, axis=1)\n",
    "df_tmp = df_tmp[df_tmp[newcol] == 'Yes']\n",
    "\n",
    "FileNames = list(df_tmp['FileName'].unique())\n",
    "print(\"len = \", len(FileNames))\n",
    "tot_ayas = len(FileNames)\n",
    "test_val_ayas = math.ceil(0.2 * tot_ayas)\n",
    "print(\"test_val_ayas = \", test_val_ayas)\n",
    "\n",
    "val_start_idx  = tot_ayas - 1 - test_val_ayas\n",
    "test_start_idx = val_start_idx - test_val_ayas\n",
    "print(\"        val_start_idx = \", val_start_idx)\n",
    "print(\"       test_start_idx = \", test_start_idx)\n",
    "Val_Ayas   = FileNames[val_start_idx+1:tot_ayas+1]\n",
    "Test_Ayas  = FileNames[test_start_idx+1:val_start_idx+1]\n",
    "Train_Ayas = FileNames[0:test_start_idx+1]\n",
    "#print(\"Val_Ayas = \", Val_Ayas)\n",
    "\n",
    "df_tmp['Set'] = df_tmp.apply(assign_set_filename, axis=1)\n",
    "\n",
    "my_out_file = os.path.join(data_dir, 'pd_df_3.xlsx')\n",
    "writer = ExcelWriter(my_out_file)\n",
    "df_tmp.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399]\n",
      "[840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReciterName</th>\n",
       "      <th>FileName</th>\n",
       "      <th>DataSizeKB</th>\n",
       "      <th>BitRate</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Mono/Stereo</th>\n",
       "      <th>Duration</th>\n",
       "      <th>FileNoExt</th>\n",
       "      <th>Sura</th>\n",
       "      <th>Aya</th>\n",
       "      <th>AyaInQuran</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>006052.mp3</td>\n",
       "      <td>343</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>43.807347</td>\n",
       "      <td>006052</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>840</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>006053.mp3</td>\n",
       "      <td>233</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>29.701224</td>\n",
       "      <td>006053</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>841</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>006054.mp3</td>\n",
       "      <td>432</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>55.170612</td>\n",
       "      <td>006054</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>842</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>006055.mp3</td>\n",
       "      <td>93</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>11.859592</td>\n",
       "      <td>006055</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>843</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>006056.mp3</td>\n",
       "      <td>231</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>29.492245</td>\n",
       "      <td>006056</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>844</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6715</th>\n",
       "      <td>FaresAbbad</td>\n",
       "      <td>007162.mp3</td>\n",
       "      <td>90</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>14.942041</td>\n",
       "      <td>007162</td>\n",
       "      <td>7</td>\n",
       "      <td>162</td>\n",
       "      <td>1115</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6716</th>\n",
       "      <td>FaresAbbad</td>\n",
       "      <td>007163.mp3</td>\n",
       "      <td>142</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>23.902041</td>\n",
       "      <td>007163</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "      <td>1116</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6717</th>\n",
       "      <td>FaresAbbad</td>\n",
       "      <td>007164.mp3</td>\n",
       "      <td>115</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>19.226122</td>\n",
       "      <td>007164</td>\n",
       "      <td>7</td>\n",
       "      <td>164</td>\n",
       "      <td>1117</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6718</th>\n",
       "      <td>FaresAbbad</td>\n",
       "      <td>007165.mp3</td>\n",
       "      <td>108</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>17.972245</td>\n",
       "      <td>007165</td>\n",
       "      <td>7</td>\n",
       "      <td>165</td>\n",
       "      <td>1118</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6719</th>\n",
       "      <td>FaresAbbad</td>\n",
       "      <td>007166.mp3</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>9.012245</td>\n",
       "      <td>007166</td>\n",
       "      <td>7</td>\n",
       "      <td>166</td>\n",
       "      <td>1119</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ReciterName    FileName  DataSizeKB  BitRate  Channels Mono/Stereo  \\\n",
       "840   AbdulBasit  006052.mp3         343       64         2      stereo   \n",
       "841   AbdulBasit  006053.mp3         233       64         2      stereo   \n",
       "842   AbdulBasit  006054.mp3         432       64         2      stereo   \n",
       "843   AbdulBasit  006055.mp3          93       64         2      stereo   \n",
       "844   AbdulBasit  006056.mp3         231       64         2      stereo   \n",
       "...          ...         ...         ...      ...       ...         ...   \n",
       "6715  FaresAbbad  007162.mp3          90       49         2      stereo   \n",
       "6716  FaresAbbad  007163.mp3         142       48         2      stereo   \n",
       "6717  FaresAbbad  007164.mp3         115       49         2      stereo   \n",
       "6718  FaresAbbad  007165.mp3         108       49         2      stereo   \n",
       "6719  FaresAbbad  007166.mp3          55       50         2      stereo   \n",
       "\n",
       "       Duration FileNoExt  Sura  Aya  AyaInQuran   Set  \n",
       "840   43.807347    006052     6   52         840  test  \n",
       "841   29.701224    006053     6   53         841  test  \n",
       "842   55.170612    006054     6   54         842  test  \n",
       "843   11.859592    006055     6   55         843  test  \n",
       "844   29.492245    006056     6   56         844  test  \n",
       "...         ...       ...   ...  ...         ...   ...  \n",
       "6715  14.942041    007162     7  162        1115  test  \n",
       "6716  23.902041    007163     7  163        1116  test  \n",
       "6717  19.226122    007164     7  164        1117  test  \n",
       "6718  17.972245    007165     7  165        1118  test  \n",
       "6719   9.012245    007166     7  166        1119  test  \n",
       "\n",
       "[1400 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### SKIP THIS IF USING FILENAMES ABOVE\n",
    "# Using Aya or Sura?\n",
    "AyaOrSura = 'Aya'\n",
    "\n",
    "#Val_Ayas   = [i for i in range(val_start_idx+1, ayaTo+1)]\n",
    "#Test_Ayas  = [i for i in range(test_start_idx+1, val_start_idx+1)]\n",
    "#Train_Ayas = [i for i in range(ayaFrom, test_start_idx+1)]\n",
    "\n",
    "#Train_Suras = [105, 106, 107, 108, 111, 113, 114]\n",
    "#Val_Suras   = [104, 110]\n",
    "#Test_Suras  = [109, 112]   \n",
    "print(Val_Ayas)\n",
    "print(Test_Ayas)\n",
    "\n",
    "df_tmp = df.copy()\n",
    "if AyaOrSura == 'Sura':\n",
    "    df_tmp['Set'] = df_tmp.apply(assign_set_sura, axis=1)\n",
    "    pass\n",
    "elif AyaOrSura == 'Aya':\n",
    "    df_tmp['Set'] = df_tmp.apply(assign_set_aya, axis=1)\n",
    "    pass\n",
    "\n",
    "display(df_tmp[df_tmp['Set'] == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test: Number of items = 61, StartIndex = 179, EndIndex = 239\n",
      "  Val: Number of items = 61, StartIndex = 240, EndIndex = 300\n",
      "Train: Number of items = 179, StartIndex = 0, EndIndex = 178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
       "       192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
       "       205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
       "       218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
       "       231, 232, 233, 234, 235, 236, 237, 238, 239], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
       "       253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
       "       266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278,\n",
       "       279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291,\n",
       "       292, 293, 294, 295, 296, 297, 298, 299, 300], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at Sura or AyaInQuran\n",
    "lookcol = 'AyaInQuran'\n",
    "\n",
    "print(\" Test: Number of items = {}, StartIndex = {}, EndIndex = {}\".format(len(df_tmp[df_tmp['Set'] == \"test\"][lookcol].unique()), df_tmp[df_tmp['Set'] == \"test\"][lookcol].unique()[0], df_tmp[df_tmp['Set'] == \"test\"][lookcol].unique()[-1] ))\n",
    "print(\"  Val: Number of items = {}, StartIndex = {}, EndIndex = {}\".format(len(df_tmp[df_tmp['Set'] == \"validation\"][lookcol].unique()), df_tmp[df_tmp['Set'] == \"validation\"][lookcol].unique()[0], df_tmp[df_tmp['Set'] == \"validation\"][lookcol].unique()[-1] ))\n",
    "print(\"Train: Number of items = {}, StartIndex = {}, EndIndex = {}\".format(len(df_tmp[df_tmp['Set'] == \"train\"][lookcol].unique()), df_tmp[df_tmp['Set'] == \"train\"][lookcol].unique()[0], df_tmp[df_tmp['Set'] == \"train\"][lookcol].unique()[-1] ))\n",
    "\n",
    "# Check(s)\n",
    "display(df_tmp[df_tmp['Set'] == \"test\"][lookcol].unique())\n",
    "display(df_tmp[df_tmp['Set'] == \"validation\"][lookcol].unique())\n",
    "display(df_tmp[df_tmp['Set'] == \"train\"][lookcol].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReciterName</th>\n",
       "      <th>FileName</th>\n",
       "      <th>DataSizeKB</th>\n",
       "      <th>BitRate</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Mono/Stereo</th>\n",
       "      <th>Duration</th>\n",
       "      <th>FileNoExt</th>\n",
       "      <th>Sura</th>\n",
       "      <th>Aya</th>\n",
       "      <th>AyaInQuran</th>\n",
       "      <th>Common</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>001001.mp3</td>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>4.336327</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>001002.mp3</td>\n",
       "      <td>42</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>5.276735</td>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>001003.mp3</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>3.996735</td>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>001004.mp3</td>\n",
       "      <td>36</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>4.519184</td>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AbdulBasit</td>\n",
       "      <td>001005.mp3</td>\n",
       "      <td>44</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>5.590204</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ReciterName    FileName  DataSizeKB  BitRate  Channels Mono/Stereo  \\\n",
       "0  AbdulBasit  001001.mp3          34       64         2      stereo   \n",
       "1  AbdulBasit  001002.mp3          42       64         2      stereo   \n",
       "2  AbdulBasit  001003.mp3          32       64         2      stereo   \n",
       "3  AbdulBasit  001004.mp3          36       64         2      stereo   \n",
       "4  AbdulBasit  001005.mp3          44       64         2      stereo   \n",
       "\n",
       "   Duration  FileNoExt  Sura  Aya  AyaInQuran Common    Set  \n",
       "0  4.336327       1001     1    1           0    Yes  train  \n",
       "1  5.276735       1002     1    2           1    Yes  train  \n",
       "2  3.996735       1003     1    3           2    Yes  train  \n",
       "3  4.519184       1004     1    4           3    Yes  train  \n",
       "4  5.590204       1005     1    5           4    Yes  train  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once satisfied with updated df_tmp, assign it back to df\n",
    "df = df_tmp.copy()\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  (305, 13)\n",
      "validation:  (305, 13)\n",
      "train:  (895, 13)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes\n",
    "print(\"test: \",df[df['Set'] == \"test\"].shape)\n",
    "print(\"validation: \",df[df['Set'] == \"validation\"].shape)\n",
    "print(\"train: \",df[df['Set'] == \"train\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 13) (305, 13) (895, 13)\n"
     ]
    }
   ],
   "source": [
    "df_test  = df[df['Set'] == \"test\"]\n",
    "df_valid = df[df['Set'] == \"validation\"]\n",
    "df_train = df[df['Set'] == \"train\"]\n",
    "\n",
    "print(df_test.shape, df_valid.shape, df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 5 ['AbdulBasit', 'AbdurrahmaanAs-Sudais', 'Ajami', 'Alafasy', 'FaresAbbad']\n",
      "Classes: 5 [0, 1, 2, 3, 4]\n",
      "\n",
      "dict_reciter_to_label =  {'AbdulBasit': 0, 'AbdurrahmaanAs-Sudais': 1, 'Ajami': 2, 'Alafasy': 3, 'FaresAbbad': 4}\n",
      "dict_label_to_reciter =  {0: 'AbdulBasit', 1: 'AbdurrahmaanAs-Sudais', 2: 'Ajami', 3: 'Alafasy', 4: 'FaresAbbad'}\n"
     ]
    }
   ],
   "source": [
    "# Encoding for the reciters as lables\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['ReciterName'])\n",
    "\n",
    "\"\"\"\n",
    "le.transform([\"tokyo\", \"tokyo\", \"paris\"])\n",
    "list(le.inverse_transform([2, 2, 1]))\n",
    "\"\"\"\n",
    "print(\"Classes:\", len(list(le.classes_)), list(le.classes_))\n",
    "print(\"Classes:\", len(list(le.classes_)), list(le.transform(le.classes_)))\n",
    "print()\n",
    "#print(le.transform(df['ReciterName']))\n",
    "\n",
    "# Create a dictionary\n",
    "dict_reciter_to_label = dict(zip(list(le.classes_), list(le.transform(le.classes_))))\n",
    "print(\"dict_reciter_to_label = \", dict_reciter_to_label)\n",
    "dict_label_to_reciter = {v: k for k, v in dict_reciter_to_label.items()}\n",
    "print(\"dict_label_to_reciter = \", dict_label_to_reciter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(le.transform(['Alafasy']))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Audio Features\n",
    "I wanted to make sure I am able to explore & switch between different features easily so there are many audio features that have been coded in the helper function below.\n",
    "\n",
    "From the data frame it is clear that the various MP3 files have different characteristics. Almost all of these need to be \"matched\" in order to get the correct data. Here is how this was acheived:\n",
    "- Bit rate (kbps)    - This didn't seem to make a difference, so nothing was done about this characteristic.\n",
    "- Sample rate (kHz)  - The sample rate needs to be the same across all audio files so features are comparable. Librosa can be given the sample rate as an input. The default is \"22050\". I left it at default so all the files will be re-sampled at this rate during the read operation.\n",
    "- Duration (seconds) - The duration needs to be the same across all audio files. Librosa by default reads the whole duration of the file. We can read a smaller duration but can't \"pad\" the duration during read. There were two options to deal with the varying durations of the audio files:\n",
    "     - Figure out min duration & only read the minimum duration.\n",
    "     - Figure out max duration & pad the duration after reading the MP3 file.\n",
    "     \n",
    "     I am choosing to go with the min duration which will help reduce the size of the data for train/test/val.\n",
    "\n",
    "Other parameters (hop_length, etc.) are related to the Librosa and were made the same during feature extraction.\n",
    "\n",
    "One other thing to note is that in order to get same data array sizes from each audio file, we first run feature extraction on one audio file to get the \"shape\" of the data array. Then the data array is initilized and real feature extraction begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.7395918367347\n",
      "167\n",
      "Max duration = 167 seconds\n",
      "2.93984126984127\n",
      "3\n",
      "Min duration = 3 seconds\n"
     ]
    }
   ],
   "source": [
    "# Before audio features can be extracted, need to figure out the longest/shortest\n",
    "# duration and make all audio same duration\n",
    "duration_max = df['Duration'].max()\n",
    "print(duration_max)\n",
    "# Round it up\n",
    "new_max_duration = math.ceil(duration_max)\n",
    "print(new_max_duration)\n",
    "print(\"Max duration = {} seconds\".format(new_max_duration))\n",
    "\n",
    "duration_min = df['Duration'].min()\n",
    "print(duration_min)\n",
    "# Round it up\n",
    "new_min_duration = math.ceil(duration_min)\n",
    "print(new_min_duration)\n",
    "print(\"Min duration = {} seconds\".format(new_min_duration))\n",
    "# %load helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reciter       =  AbdulBasit\n",
      "mp3_file      =  001001.mp3\n",
      "read_duration =  30\n",
      "pad_duration  =  30\n",
      "        shp_0 =  None\n",
      "        shp_1 =  None\n",
      "           sr =  22050\n",
      "        n_fft =  2048\n",
      "       n_mfcc =  13\n",
      "   hop_length =  1024\n",
      "features_list =  ['mfcc']\n"
     ]
    }
   ],
   "source": [
    "# Run feature extraction on one audio file to get the \"shape\" of the data array\n",
    "#reciter = df[0]['ReciterName']\n",
    "reciter = df.lookup([0], ['ReciterName'])[0]\n",
    "mp3_file = df.lookup([0], ['FileName'])[0]\n",
    "#read_duration = pad_duration = new_min_duration\n",
    "read_duration = pad_duration = 30\n",
    "shp_0 = shp_1 = None\n",
    "sr = 22050\n",
    "n_fft = 2048\n",
    "n_mfcc = 13\n",
    "hop_length = 1024\n",
    "features_list = ['mfcc']\n",
    "\n",
    "print(\"reciter       = \", reciter)\n",
    "print(\"mp3_file      = \", mp3_file)\n",
    "print(\"read_duration = \", read_duration)\n",
    "print(\"pad_duration  = \", pad_duration)\n",
    "print(\"        shp_0 = \", shp_0)\n",
    "print(\"        shp_1 = \", shp_1)\n",
    "print(\"           sr = \", sr)\n",
    "print(\"        n_fft = \", n_fft)\n",
    "print(\"       n_mfcc = \", n_mfcc)\n",
    "print(\"   hop_length = \", hop_length)\n",
    "print(\"features_list = \", features_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shp[0] : 13\n",
      "new_shp_0 : 13\n",
      "new_shp_1 : 646\n",
      "reciter INIT:\n",
      "<class 'list'>\n",
      "shape 0/1 :\n",
      "13 646\n"
     ]
    }
   ],
   "source": [
    "columns, data, feature_shapes, new_shp_0, new_shp_1 = extract_audio_features(\n",
    "    reciter=reciter, mp3_file=mp3_file, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, \n",
    "    hop_length=hop_length, pad_duration=pad_duration, read_duration=read_duration, \n",
    "    features_list=features_list, shp_0=shp_0, shp_1=shp_1)\n",
    "print(\"reciter INIT:\")\n",
    "print(type(data))\n",
    "#print(data.shape)\n",
    "print(\"shape 0/1 :\")\n",
    "print(new_shp_0, new_shp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shp0 shp1 =  13 646\n",
      "X_arr initialized to : (0, 646, 13)\n",
      "reciters_arr initialized to : (0, 5)\n",
      "Processed  100\n",
      "Processed  200\n",
      "Processed  300\n",
      "DONE in 1.18e+02 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "X_test, y_test = gen_audio_data(df_test, shp0=new_shp_0, shp1=new_shp_1)\n",
    "print(\"DONE in {:0.3} sec\\n\".format(time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 646, 13) (305, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(data_dir, 'test_arr'), X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shp0 shp1 =  13 646\n",
      "X_arr initialized to : (0, 646, 13)\n",
      "reciters_arr initialized to : (0, 5)\n",
      "Processed  100\n",
      "Processed  200\n",
      "Processed  300\n",
      "DONE in 1.13e+02 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "X_valid, y_valid = gen_audio_data(df_valid, shp0=new_shp_0, shp1=new_shp_1)\n",
    "print(\"DONE in {:0.3} sec\\n\".format(time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 646, 13) (305, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(data_dir, 'valid_arr'), X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shp0 shp1 =  13 646\n",
      "X_arr initialized to : (0, 646, 13)\n",
      "reciters_arr initialized to : (0, 5)\n",
      "Processed  100\n",
      "Processed  200\n",
      "Processed  300\n",
      "Processed  400\n",
      "Processed  500\n",
      "Processed  600\n",
      "Processed  700\n",
      "Processed  800\n",
      "DONE in 3.12e+02 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "X_train, y_train = gen_audio_data(df_train, shp0=new_shp_0, shp1=new_shp_1)\n",
    "print(\"DONE in {:0.3} sec\\n\".format(time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(895, 646, 13) (895, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(data_dir, 'train_arr'), X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.864203307980052e-72 1.0198236647671823e+22 1.5216094321311794e+16\n"
     ]
    }
   ],
   "source": [
    "# Convert the scale of training data\n",
    "X_train_raw = librosa.core.db_to_power(X_train, ref=1.0)\n",
    "print(np.amin(X_train_raw), np.amax(X_train_raw), np.mean(X_train_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-164.20422375326532 50.67650178054088 -6.3850888847565175\n"
     ]
    }
   ],
   "source": [
    "X_train_log = np.log(X_train_raw)\n",
    "print(np.amin(X_train_log), np.amax(X_train_log), np.mean(X_train_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_raw = librosa.core.db_to_power(X_valid, ref=1.0)\n",
    "X_valid_log = np.log(X_valid_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = unison_shuffled_copies(X_train_log, y_train)\n",
    "X_valid, y_valid = unison_shuffled_copies(X_valid_log, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes are:  (895, 646, 13) (305, 646, 13) (895, 5) (305, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes are: \", X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(data_dir, 'shuffled_train_log'), X_train, y_train)\n",
    "np.savez(os.path.join(data_dir, 'shuffled_valid_log'), X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't use db_to_power, just use the raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-164.20422375326532 50.67650178054088 -6.385088884756508\n"
     ]
    }
   ],
   "source": [
    "# Convert the scale of training data\n",
    "X_train_raw = X_train\n",
    "print(np.amin(X_train_raw), np.amax(X_train_raw), np.mean(X_train_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-164.20422375326532 50.67650178054088 -6.385088884756508\n"
     ]
    }
   ],
   "source": [
    "X_train_log = X_train_raw\n",
    "print(np.amin(X_train_log), np.amax(X_train_log), np.mean(X_train_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_raw = X_valid\n",
    "X_valid_log = X_valid_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = unison_shuffled_copies(X_train_log, y_train)\n",
    "X_valid, y_valid = unison_shuffled_copies(X_valid_log, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes are:  (895, 646, 13) (305, 646, 13) (895, 5) (305, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes are: \", X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(data_dir, 'shuffled_train'), X_train, y_train)\n",
    "np.savez(os.path.join(data_dir, 'shuffled_valid'), X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
