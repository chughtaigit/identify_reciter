{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quran Reciter Identification (Speech Recognition) using Machine Learning\n",
    "#### by Muhammad Khurram Chughtai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2_Data_Preparation\n",
    "This notebook prepares the data for training in the following steps:\n",
    "- Quick look at the downloaded data & select 5 reciters from the downloaded data\n",
    "- Select the Sura/Aya for the reciters\n",
    "- Mark the data for training/validation/test such that the same Sura/Aya are used for each reciter\n",
    "- Select the feature(s) to be extracted\n",
    "- Extract the feature(s)\n",
    "- Save the train/val/test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quran organization\n",
    "Before looking at the data, it is important to understand how Quran is organized and some related terms which will help make sense of the data.\n",
    "\n",
    "Quran is the holy book of religion of Islam. It is organized as follows:\n",
    "- Quran is dvided into \"suras\" (chapters) with unque names for each sura. e.g. the first sura has the name \"Al-Fatiha\" (The Opening). There are 114 suras.\n",
    "- Each \"sura\" (chapter) consists of at least 3 or more \"ayas\" (verses). Each \"aya\" (verse) consists of one or more Arabic sentences. e.g. the first surah \"Al-Fatiha\" consists of 7 ayas. There are total of 6,236 ayas in all 114 suras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading all the helper procedures into the Notebook.\n",
    "Loading helper procedures from helpers.py:\n",
    "- Create a new cell & execute the following line\n",
    "        %load helpers.py\n",
    "- This will put the contents of the file in the cell. Then execute the cell to load everything in memory\n",
    "\n",
    "**Note**: Start by cutting the cell below to replace it with empty new cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helpers.py LOADED!\n"
     ]
    }
   ],
   "source": [
    "# %load helpers.py\n",
    "##################\n",
    "# imports\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import pathlib\n",
    "import xml.etree.ElementTree as ET\n",
    "import zipfile\n",
    "import shutil\n",
    "import librosa\n",
    "import math\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "import audioread\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import ExcelWriter\n",
    "from pydub.utils import mediainfo\n",
    "\n",
    "##################\n",
    "# Default Constants\n",
    "# Directory where MP3 files have been downloaded\n",
    "zip_data_dir   = '../DownloadedReciters'\n",
    "# Name of ZIP file for each reciter\n",
    "zip_file_name  = '000_versebyverse.zip'\n",
    "# Directory where processed data & other generated data will be stored\n",
    "data_dir       = '../data'\n",
    "audio_data_dir = os.path.join(os.getcwd(), data_dir, \"audio\")\n",
    "quran_meta_xml = os.path.join(os.getcwd(), 'Qurandata', \"quran-data.xml\")\n",
    "# Max/Min number of Sura/Aya with first as index 1\n",
    "SuraIndexMIN   = 1\n",
    "SuraIndexMAX   = 114\n",
    "AyaIndexMIN    = 0\n",
    "AyaIndexMAX    = 6236\n",
    "\n",
    "# Suppress this warning from librosa:\n",
    "# UserWarning: PySoundFile failed. Trying audioread instead.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "##################\n",
    "# Functions\n",
    "def qsura_ayat_to_labels(suraFrom=None, suraTo=None, ayaFrom=None, ayaTo=None):\n",
    "    \"\"\" Converts either Sura or Aya numbers to labels.\n",
    "\n",
    "       :param suraFrom: An interger for Sura index to start from. Valid numbers are 1 to 114 (default: None)\n",
    "       :type suraFrom: int\n",
    "       :param suraTo: An interger for Sura index to end to. Valid numbers are 1 to 114 (inclusive) (default: None)\n",
    "       :type suraTo: int\n",
    "       :param ayaFrom: An interger for Aya index to start from (default: None)\n",
    "       :type ayaFrom: int\n",
    "       :param ayaTo: An interger for Aya index to end to (inclusive) (default: None)\n",
    "       :type ayaTo: int\n",
    "       :return: A list of labels in the form ['001001', '001002', ...], A list of aya number in quran [0, 2, ... AyaIndexMAX]\n",
    "       :rtype: list, list \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Return lists\n",
    "    labels_list = list()\n",
    "    ayainq = list()\n",
    "\n",
    "    useSura = False\n",
    "    useAya = False\n",
    "    if suraFrom is not None and suraTo is not None:\n",
    "        if suraFrom < SuraIndexMIN or suraFrom > SuraIndexMAX:\n",
    "            print(\"ERROR: {} not between {} and {}\".format('suraFrom', SuraIndexMIN,SuraIndexMAX))\n",
    "            return labels_list, ayainq\n",
    "        if suraTo < SuraIndexMIN or suraTo > SuraIndexMAX:\n",
    "            print(\"ERROR: {} not between {} and {}\".format('suraTo', SuraIndexMIN,SuraIndexMAX))\n",
    "            return labels_list, ayainq\n",
    "        useSura = True\n",
    "    elif ayaFrom is not None and ayaTo is not None:\n",
    "        if ayaFrom < AyaIndexMIN or ayaFrom > AyaIndexMAX:\n",
    "            print(\"ERROR: {} not between {} and {}\".format('ayaFrom', AyaIndexMIN,AyaIndexMAX))\n",
    "            return labels_list, ayainq\n",
    "        if ayaTo < AyaIndexMIN or ayaTo > AyaIndexMAX:\n",
    "            print(\"ERROR: {} not between {} and {}\".format('ayaTo', AyaIndexMIN,AyaIndexMAX))\n",
    "            return labels_list, ayainq\n",
    "        useAya = True\n",
    "\n",
    "    ##################\n",
    "    # qmeta: Quran Meta Data\n",
    "    qmeta_tree = ET.parse(quran_meta_xml)\n",
    "    qmeta_root = qmeta_tree.getroot()\n",
    "    #print(\"qmeta_root :\", qmeta_root)\n",
    "\n",
    "    # As an Element, root has a tag and a dictionary of attributes:\n",
    "    qmeta_root_tag = qmeta_root.tag\n",
    "    qmeta_root_att = qmeta_root.attrib\n",
    "    #print(\"qmeta_root_tag = \" + qmeta_root_tag)\n",
    "    #print(\"qmeta_root_att = \")\n",
    "    #print(qmeta_root_att)\n",
    "\n",
    "    # It also has children nodes over which we can iterate:\n",
    "    for qmeta_suras in qmeta_root:\n",
    "        qmeta_suras_tag = qmeta_suras.tag\n",
    "        #qmeta_suras_att = qmeta_suras.attrib\n",
    "        #print(\"qmeta_suras_tag = \" + qmeta_suras_tag)\n",
    "        #print(\"qmeta_suras_att = \")\n",
    "        #print(qmeta_suras_att)\n",
    "        if qmeta_suras_tag == \"suras\":\n",
    "            for qmeta_sura in qmeta_suras:\n",
    "                qmeta_sura_tag = qmeta_sura.tag\n",
    "                #qmeta_sura_att = qmeta_sura.attrib\n",
    "                #print(\"qmeta_sura_tag = \" + qmeta_sura_tag)\n",
    "                #print(\"qmeta_sura_att = \")\n",
    "                #print(qmeta_sura_att)\n",
    "                if qmeta_sura_tag == \"sura\":\n",
    "                    #print(\"qmeta_sura :\", qmeta_sura)\n",
    "                    qmeta_sura_index = qmeta_sura.attrib.get('index')\n",
    "                    qmeta_sura_ayas = qmeta_sura.attrib.get('ayas')\n",
    "                    qmeta_sura_start = qmeta_sura.attrib.get('start')\n",
    "                    #print(\"qmeta_sura_index :\", qmeta_sura_index)\n",
    "                    #print(\"qmeta_sura_ayas :\", qmeta_sura_ayas)\n",
    "                    #print(\"qmeta_sura_start :\", qmeta_sura_start)\n",
    "\n",
    "                    if useSura:\n",
    "                        if int(qmeta_sura_index) >= suraFrom and int(qmeta_sura_index) <= suraTo:\n",
    "                            #print(\"  MKC: qmeta_sura_index :\", qmeta_sura_index)\n",
    "                            #print(\"  MKC: qmeta_sura_ayas :\", qmeta_sura_ayas)\n",
    "                            #print(\"  MKC: qmeta_sura_start :\", qmeta_sura_start)\n",
    "                            for i in range(1, int(qmeta_sura_ayas)+1):\n",
    "                                labels_list.append(\"{:03d}{:03d}\".format(int(qmeta_sura_index), i))\n",
    "\n",
    "                    if useAya:\n",
    "                        # Get the current sura end ayat\n",
    "                        sura_start = int(qmeta_sura_start)\n",
    "                        sura_end = sura_start + (int(qmeta_sura_ayas) - 1)\n",
    "                        #print(\"sura start -> end: {} -> {}\".format(sura_start, sura_end))\n",
    "                        for i in range(sura_start, sura_end+1):\n",
    "                            if i >= ayaFrom and i <= ayaTo:\n",
    "                                #print(\"  -> \",i)\n",
    "                                ayainq.append(i)\n",
    "                                labels_list.append(\"{:03d}{:03d}\".format(int(qmeta_sura_index), i+1-sura_start))\n",
    "\n",
    "    #print(\"labels_list :\", labels_list)\n",
    "    return labels_list, ayainq\n",
    "\n",
    "def report_stats_zip_data(zip_data_dir=zip_data_dir, zip_file_name=zip_file_name):\n",
    "    \"\"\" Reports statitics for the zipped data\n",
    "\n",
    "       :param zip_data_dir: Directory containing the zipped data\n",
    "       :type zip_data_dir: str\n",
    "       :param zip_file_name: Name of the zip file in the directory\n",
    "       :type zip_file_name: str\n",
    "       :return: A list of directory names in zip_data_dir\n",
    "       :rtype: list \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Return list\n",
    "    dir_names = list()\n",
    "\n",
    "    # Directory names are also names of the reciters\n",
    "    print(\"{:30s} {:10s} {:8s} {:9s}\".format(\"Reciter name\", \"Data Size\", \"Files\", \"MP3 Files\"))\n",
    "    print(\"{:30s} {:10s} {:8s} {:9s}\".format(\"============\", \"=========\", \"=====\", \"=========\"))\n",
    "    for dd in os.listdir(zip_data_dir):\n",
    "        # Each directory has one zip file called 000_versebyverse.zip\n",
    "        dd_zip_file = zip_data_dir + \"/\" + dd + \"/\" + zip_file_name\n",
    "        # Size\n",
    "        dd_size_bytes = os.path.getsize(dd_zip_file)\n",
    "        dd_size_MB = dd_size_bytes / (1024 * 1024)\n",
    "        # Number of files\n",
    "        archive = zipfile.ZipFile(dd_zip_file, 'r')\n",
    "        num_files = len(archive.namelist())\n",
    "        # Mp3 files\n",
    "        mp3_cnt = 0\n",
    "        for ff in archive.namelist():\n",
    "            if ff.endswith('.mp3'):\n",
    "                mp3_cnt += 1\n",
    "\n",
    "        print(\"{:30s} {:6.0f} MB {:6d} {:12d}\".format(dd, dd_size_MB, num_files, mp3_cnt))\n",
    "        dir_names.append(dd)\n",
    "    return dir_names\n",
    "\n",
    "# Directory size (https://stackoverflow.com/questions/1392413/calculating-a-directorys-size-using-python)\n",
    "def get_dir_size(start_path = '.'):\n",
    "    \"\"\" Gets the size of the directory recursively\n",
    "\n",
    "       :param start_path: Path to a directory whose size is needed\n",
    "       :type start_path: str\n",
    "       :return: Total size of the directory in bytes\n",
    "       :rtype: int\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # skip if it is symbolic link\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "def report_stats_audio_data(data_dir=audio_data_dir, verbose=False):\n",
    "    \"\"\" Reports statitics for the audio data\n",
    "\n",
    "       :param data_dir: Directory containing the audio data\n",
    "       :type data_dir: str\n",
    "       :return: DataFrame with audio directory details\n",
    "       :rtype: DataFrame \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    column_names = list()\n",
    "    column_names.append('ReciterName')\n",
    "    column_names.append('FileName')\n",
    "    column_names.append('DataSizeKB')\n",
    "    column_names.append('BitRate')\n",
    "    column_names.append('Channels')\n",
    "    column_names.append('Mono/Stereo')\n",
    "    column_names.append('Duration')\n",
    "    column_names.append('FileNoExt')\n",
    "    column_names.append('Sura')\n",
    "    column_names.append('Aya')\n",
    "    column_names.append('AyaInQuran')\n",
    "\n",
    "    sv_reciter   = list()\n",
    "    sv_file_name = list()\n",
    "    sv_data_size = list()\n",
    "    sv_bit_rate  = list()\n",
    "    sv_ch        = list()\n",
    "    sv_ms        = list()\n",
    "    sv_dur       = list()\n",
    "    sv_filenoext = list()\n",
    "    sv_sura      = list()\n",
    "    sv_aya       = list()\n",
    "    sv_ayainq    = list()\n",
    "\n",
    "    # Directory names are also names of the reciters\n",
    "    print(\"{:30s} {:10s} {:4s} {:4s} {:2s} {:6s} {:9s}\".format(\"Reciter name/MP3 File\", \"Data Size\", \"MP3s\", \"kbps\", \"Ch\", \"Mono/S\", \"Duration(sec)\"))\n",
    "    print(\"{:30s} {:10s} {:4s} {:4s} {:2s} {:6s} {:9s}\".format(\"==============================\", \"=========\", \"====\", \"====\", \"==\", \"======\", \"=============\"))\n",
    "    for dd in os.listdir(data_dir):\n",
    "        reciter_dir = os.path.join(data_dir, dd)\n",
    "        # Size\n",
    "        #dd_size_bytes = os.path.getsize(reciter_dir)\n",
    "        dd_size_bytes = get_dir_size(reciter_dir)\n",
    "        dd_size_KB = dd_size_bytes / (1024)\n",
    "        # Number of files\n",
    "        num_files = len(os.listdir(reciter_dir))\n",
    "        # Mp3 files\n",
    "        mp3_cnt = 0\n",
    "        for ff in os.listdir(reciter_dir):\n",
    "            if ff.endswith('.mp3'):\n",
    "                mp3_cnt += 1\n",
    "\n",
    "        print(\"{:30s} {:6.0f} KB {:5d}\".format(dd, dd_size_KB, mp3_cnt))\n",
    "\n",
    "        for ff in os.listdir(reciter_dir):\n",
    "            if not ff.endswith('.mp3'):\n",
    "                continue\n",
    "            mp3_file = os.path.join(reciter_dir, ff)\n",
    "\n",
    "            duration = channel_layout = bit_rate = channels = bit_rate_kbps = -1\n",
    "            try:\n",
    "                # Look at some audio features\n",
    "                y, sr = librosa.load(mp3_file, sr=None)\n",
    "                # Get the length of the audio\n",
    "                duration = librosa.core.get_duration(y=y, sr=sr)\n",
    "                duration = len(y) / sr\n",
    "\n",
    "                # Sample rate\n",
    "                info = mediainfo(mp3_file)\n",
    "                #print(info)\n",
    "                channel_layout = info['channel_layout']\n",
    "                bit_rate = int(info['bit_rate'])\n",
    "                channels = int(info['channels'])\n",
    "                #artist = info['artist']\n",
    "                artist = \"\"\n",
    "                bit_rate_kbps = bit_rate / 1000\n",
    "            \n",
    "            except:\n",
    "                print(\"Couldn't process, skipping: \", mp3_file)\n",
    "\n",
    "            #print(\"{:>30s} {:6.0f} KB {:5d} {:12d} {:5.1f}\".format(ff, dd_size_KB, 0, int(info['sample_rate']), duration))\n",
    "            #with audioread.audio_open(mp3_file) as input_file:\n",
    "            #    sr_native = input_file.samplerate\n",
    "            #    n_channels = input_file.channels\n",
    "            #print(sr_native, n_channels)\n",
    "            if verbose == True:\n",
    "                print(\"{:>30s} {:6.0f} KB {:5s} {:4.0f} {:2d} {:6s} {:13.1f}\".format(ff, dd_size_KB, \"\", bit_rate_kbps, channels, channel_layout, duration))\n",
    "\n",
    "            # Size\n",
    "            dd_size_bytes = os.path.getsize(mp3_file)\n",
    "            dd_size_KB = dd_size_bytes / (1024)\n",
    "\n",
    "            sv_reciter.append(dd)\n",
    "            sv_file_name.append(ff)\n",
    "            sv_data_size.append(int(dd_size_KB))\n",
    "            sv_bit_rate.append(int(bit_rate_kbps))\n",
    "            sv_ch.append(channels)\n",
    "            sv_ms.append(channel_layout)\n",
    "            sv_dur.append(duration)\n",
    "            filenoext, sura, aya, ayainq = get_mp3_file_info(ff)\n",
    "            sv_filenoext.append(filenoext)\n",
    "            sv_sura.append(sura)\n",
    "            sv_aya.append(aya)\n",
    "            sv_ayainq.append(ayainq)\n",
    "            #break\n",
    "        #break\n",
    "    \n",
    "    # Create a DataFrame with all the info\n",
    "    df = pd.DataFrame(list(zip(sv_reciter, sv_file_name, sv_data_size, \n",
    "        sv_bit_rate, sv_ch, sv_ms, sv_dur, sv_filenoext, sv_sura, sv_aya, sv_ayainq)), \n",
    "               columns=column_names) \n",
    "\n",
    "    return df\n",
    "\n",
    "def get_mp3_file_info(file_name):\n",
    "    \"\"\" Get info from MP3 file name. Use lbl_aya_dict dictionary for lookup so this variable needs to be defined before.\n",
    "\n",
    "       :param file_name: MP3 file name\n",
    "       :type file_name: str\n",
    "       :return: label, sura, aya, ayainquran\n",
    "       :rtype: str \n",
    "\n",
    "    File name should be ######.mp3, e.g. 001004.mp3\n",
    "        SuraAya    = 001004\n",
    "        Sura       = 1\n",
    "        Aya        = 4\n",
    "        AyaInQuran = 3\n",
    "    \"\"\"\n",
    "\n",
    "    # Return items\n",
    "    suraaya   = ''\n",
    "    sura      = -1\n",
    "    aya       = -1\n",
    "    ayainquan = -1\n",
    "\n",
    "    suraaya = os.path.splitext(file_name)[0]\n",
    "    sura = int(suraaya[:3])\n",
    "    aya  = int(suraaya[3:])\n",
    "    ayainquan = int(lbl_aya_dict[suraaya])\n",
    "\n",
    "    return suraaya, sura, aya, ayainquan\n",
    "\n",
    "def audio_data_initialize(dir_name=audio_data_dir):\n",
    "    \"\"\" Initialize audio data directory\n",
    "\n",
    "       :param dir_name: Directory name to initialize\n",
    "       :type dir_name: str\n",
    "       :return: dir_name\n",
    "       :rtype: str \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # If directory exists, delete the directory \n",
    "    if pathlib.Path(dir_name).exists():\n",
    "        print(\"Directory exists, deleting :\", dir_name)\n",
    "        #pathlib.Path(dir_name).rmdir()\n",
    "        shutil.rmtree(dir_name)\n",
    "\n",
    "    # Create the directory\n",
    "    print(\"Creating directory :\", dir_name)\n",
    "    pathlib.Path(dir_name).mkdir()\n",
    "\n",
    "    return dir_name\n",
    "\n",
    "def populate_audio_files(zip_data_dir=zip_data_dir, zip_file_name=zip_file_name, \n",
    "        audio_data_dir=audio_data_dir, reciters=None, suraFrom=None, suraTo=None,\n",
    "        ayaFrom=None, ayaTo=None):\n",
    "    \"\"\" Populate audio files for the reciters in the given directory.\n",
    "\n",
    "       :param zip_data_dir: Directory containing the zipped data\n",
    "       :type zip_data_dir: str\n",
    "       :param zip_file_name: Name of the zip file in the directory\n",
    "       :type zip_file_name: str\n",
    "       :param audio_data_dir: Name of the download directory with the reciter zip files\n",
    "       :type audio_data_dir: str\n",
    "       :param reciters: Name(s) of the reciters. Only their data will be processed, rest will be ignored\n",
    "       :type reciters: list of strings\n",
    "       :param suraFrom: Starting sura\n",
    "       :type suraFrom: int\n",
    "       :param suraTo: Ending sura\n",
    "       :type suraTo: int\n",
    "       :param ayaFrom: Starting aya\n",
    "       :type ayaFrom: int\n",
    "       :param ayaTo: Ending aya\n",
    "       :type ayaTo: int\n",
    "       :return: None\n",
    "       :rtype: None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert SuraAya.mp3 name to AyaInQuran \n",
    "    audio_labels, ayainq_list = qsura_ayat_to_labels(suraFrom=suraFrom, suraTo=suraTo, \n",
    "        ayaFrom=ayaFrom, ayaTo=ayaTo)\n",
    "    #print(\"Audio labels: \", audio_labels)\n",
    "    #print(\"Aya in Quran labels: \", ayainq_list)\n",
    "\n",
    "    for dd in os.listdir(zip_data_dir):\n",
    "        if dd not in reciters:\n",
    "            continue\n",
    "\n",
    "        print(\"Found reciter: \", dd)\n",
    "        # Create the directory\n",
    "        reciter_dir = os.path.join(audio_data_dir, dd)\n",
    "        print(\"Creating directory :\", reciter_dir)\n",
    "        pathlib.Path(reciter_dir).mkdir()\n",
    "\n",
    "        # Each directory has one zip file called 000_versebyverse.zip\n",
    "        dd_zip_file = zip_data_dir + \"/\" + dd + \"/\" + zip_file_name\n",
    "        # Size\n",
    "        dd_size_bytes = os.path.getsize(dd_zip_file)\n",
    "        dd_size_MB = dd_size_bytes / (1024 * 1024)\n",
    "        # Number of files\n",
    "        archive = zipfile.ZipFile(dd_zip_file, 'r')\n",
    "        num_files = len(archive.namelist())\n",
    "        # Mp3 files\n",
    "        mp3_cnt = 0\n",
    "        for ff in archive.namelist():\n",
    "            if ff.endswith('.mp3'):\n",
    "                mp3_cnt += 1\n",
    "\n",
    "        print(\"{:30s} {:6.0f} MB {:6d} {:12d}\".format(dd, dd_size_MB, num_files, mp3_cnt))\n",
    "\n",
    "        num_files_extracted = 0\n",
    "        for lbl in audio_labels:\n",
    "            mp3_file = lbl + \".mp3\"\n",
    "            if mp3_file not in archive.namelist():\n",
    "                print(\"ERROR: Couldn't find file: \", mp3_file)\n",
    "                continue\n",
    "            archive.extract(mp3_file, path=reciter_dir)\n",
    "            num_files_extracted += 1\n",
    "        print(\"{} files extracted\".format(num_files_extracted))\n",
    "    print()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_audio_features(reciter, mp3_file, sr=22050, n_mfcc=13, n_fft=2048, hop_length=512,\n",
    "    pad_duration=None, read_duration=None, features_list=['mfcc', 'zcr', 'spectral_center', \n",
    "    'spectral_rolloff', 'chroma', 'spectral_bandwidth_2', 'spectral_bandwidth_3', \n",
    "    'spectral_bandwidth_4', 'spectral_contrast'], shp_0=None, shp_1=None, normalization=True):\n",
    "    \"\"\" Extract the requested audio features.\n",
    "\n",
    "       :param reciter: Name of the reciter\n",
    "       :type reciter: str\n",
    "       :param mp3_file: Name of the mp3_file\n",
    "       :type mp3_file: str\n",
    "       :param sr: Sampling rate to apply during audio file read with librosa\n",
    "       :type sr: int\n",
    "       :param n_mfcc: Number of MFCC features to return by librosa\n",
    "       :type n_mfcc: int\n",
    "       :param n_fft: Number of Fast Frourier Transform frequeny bins to use with librosa\n",
    "       :type n_fft: int\n",
    "       :param hop_length: hop_length for librosa. This says how much to overlap audio frame windows during feature extraction.\n",
    "       :type hop_length: int\n",
    "       :param pad_duration: Pad the duration to this number if the duration of the MP3 file is shorter\n",
    "       :type pad_duration: int\n",
    "       :param read_duration: Read only this much duration from the audio file\n",
    "       :type read_duration: int\n",
    "       :param features_list: List of features to extract\n",
    "       :type features_list: list\n",
    "       :param shp_0: Initialize the return data NumPy array with this shape\n",
    "       :type shp_0: int\n",
    "       :param shp_1: Initialize the return data NumPy array with this shape\n",
    "       :type shp_1: int\n",
    "       :param normalization: Normalize the MFCC data. Only works for the MFCC feature\n",
    "       :type normalization: bool\n",
    "       :return: columns, data, feature_shapes, new_shp_0, new_shp_1\n",
    "       :rtype: list, NumPy array, list, int, int\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # File name is dir/reciter/mp3_file\n",
    "    file_name = os.path.join(audio_data_dir, reciter, mp3_file)\n",
    "\n",
    "    # Initilize return variables\n",
    "    columns = data = feature_shapes = new_shp_0 = new_shp_1 = None\n",
    "\n",
    "    # Few MP3 files for few reciters were corrupted. Give a message about them & bail out\n",
    "    try:\n",
    "        y , sr = librosa.load(file_name, sr=sr, duration=read_duration)\n",
    "        orig_duration = len(y) / sr\n",
    "        #print(\"pad_duration = \", pad_duration)\n",
    "        #print(\"read_duration = \", read_duration)\n",
    "        #print(\"orig_duration = \", orig_duration)\n",
    "        # Pad the duration\n",
    "        if pad_duration is not None:\n",
    "            if pad_duration > orig_duration:\n",
    "                new_len_y = pad_duration * sr\n",
    "                y = librosa.util.fix_length(y, new_len_y)\n",
    "            elif pad_duration <= orig_duration:\n",
    "                # Nothing to be done!\n",
    "                pass\n",
    "        duration = len(y) / sr\n",
    "        #print(\"FINAL: duration = \", duration)\n",
    "\n",
    "        # Column names\n",
    "        columns = list()\n",
    "\n",
    "        # Feature shapes\n",
    "        feature_shapes = list()\n",
    "\n",
    "        #print(\"shp_0 :\", shp_0)\n",
    "        #print(\"shp_1 :\", shp_1)\n",
    "        if shp_0 is not None and shp_1 is not None:\n",
    "            if 'spect' in features_list:\n",
    "                #data = np.empty(\n",
    "                #    (shp_0, shp_1), dtype=np.float64\n",
    "                #)\n",
    "                data = np.empty(\n",
    "                    (shp_1, shp_0), dtype=np.float64\n",
    "                )\n",
    "            else:\n",
    "                data = np.zeros(\n",
    "                    (shp_1, shp_0), dtype=np.float64\n",
    "                )\n",
    "            #data = np.empty(\n",
    "            #  (0, shp_0, shp_1)\n",
    "            #)\n",
    "            #print(\"data initialized:\")\n",
    "            #print(type(data))\n",
    "            #print(data.shape)\n",
    "        else:\n",
    "            data = list()\n",
    "            #print(type(data))\n",
    "\n",
    "        # Start index is 0 and gets updated after feature is concatenated to \"data\"\n",
    "        start_idx = 0\n",
    "        if 'mfcc' in features_list:\n",
    "            #spect = librosa.feature.melspectrogram(y=y, sr=sr,n_fft=n_fft, hop_length=hop_length)\n",
    "            mfcc = librosa.feature.mfcc(\n",
    "                y=y, sr=sr, hop_length=hop_length, n_mfcc=n_mfcc, n_fft=n_fft\n",
    "            )\n",
    "            feature_shapes.append(mfcc.shape)\n",
    "            #print(\"mfcc:\")\n",
    "            #print(mfcc.shape)\n",
    "            #print(\"mfcc.T:\")\n",
    "            #print(mfcc.T)\n",
    "            #print(\"mfcc:\")\n",
    "            #print(mfcc)\n",
    "            #print(np.amin(mfcc), np.amax(mfcc), np.mean(mfcc))\n",
    "            # Normalize?\n",
    "            if normalization == True:\n",
    "                divby = abs(np.amin(mfcc))\n",
    "                if abs(np.amax(mfcc)) > divby:\n",
    "                    divby = abs(np.amax(mfcc))\n",
    "\n",
    "                #print(\"divby = \", divby)\n",
    "                mfcc_orig = mfcc\n",
    "                x = mfcc / divby\n",
    "                #print(\"x = \", x)\n",
    "                #x = mfcc / math.abs()\n",
    "                mfcc = x\n",
    "            for i in range(1, mfcc.shape[0]+1):\n",
    "                columns.append('mfcc{}'.format(i))\n",
    "            if shp_0 is not None:\n",
    "                #data = np.append(data, [mfcc.T], axis=0)\n",
    "                data[:, start_idx:start_idx+mfcc.shape[0]] = mfcc.T[0:mfcc.shape[1], :]\n",
    "                start_idx += mfcc.shape[0]\n",
    "                #print(\"mfcc start_idx updated to: \", start_idx)\n",
    "        if 'zcr' in features_list:\n",
    "            zcr = librosa.feature.zero_crossing_rate(y)\n",
    "            feature_shapes.append(zcr.shape)\n",
    "            #print(\"zcr:\")\n",
    "            #print(zcr.shape)\n",
    "            #print(zcr.T)\n",
    "            #print(zcr.shape[1])\n",
    "            columns.append('zcr')\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+zcr.shape[0]] = zcr.T[0:zcr.shape[1], :]\n",
    "                start_idx += zcr.shape[0]\n",
    "                #print(\"zcr start_idx updated to: \", start_idx)\n",
    "        if 'spectral_center' in features_list:\n",
    "            spectral_center = librosa.feature.spectral_centroid(\n",
    "                y=y, sr=sr, hop_length=hop_length\n",
    "            )\n",
    "            feature_shapes.append(spectral_center.shape)\n",
    "            #print(\"spectral_center:\")\n",
    "            #print(spectral_center.shape)\n",
    "            columns.append('spectral_center')\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+spectral_center.shape[0]] = spectral_center.T[0:spectral_center.shape[1], :]\n",
    "                start_idx += spectral_center.shape[0]\n",
    "                #print(\"spectral_center start_idx updated to: \", start_idx)\n",
    "        if 'spectral_rolloff' in features_list:\n",
    "            #spectral_rolloff = librosa.feature.spectral_rolloff(y+0.01, sr=sr)[0]\n",
    "            spectral_rolloff = librosa.feature.spectral_rolloff(y+0.01, sr=sr)\n",
    "            feature_shapes.append(spectral_rolloff.shape)\n",
    "            #print(\"spectral_rolloff:\")\n",
    "            #print(spectral_rolloff.shape)\n",
    "            #print(spectral_rolloff)\n",
    "            columns.append('spectral_rolloff')\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+spectral_rolloff.shape[0]] = spectral_rolloff.T[0:spectral_rolloff.shape[1], :]\n",
    "                start_idx += spectral_rolloff.shape[0]\n",
    "                #print(\"spectral_rolloff start_idx updated to: \", start_idx)\n",
    "        if 'chroma' in features_list:\n",
    "            chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=hop_length)\n",
    "            feature_shapes.append(chroma.shape)\n",
    "            #print(\"chroma:\")\n",
    "            #print(chroma.shape)\n",
    "            for i in range(1, chroma.shape[0]+1):\n",
    "                columns.append('chroma{}'.format(i))\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+chroma.shape[0]] = chroma.T[0:chroma.shape[1], :]\n",
    "                start_idx += chroma.shape[0]\n",
    "                #print(\"chroma start_idx updated to: \", start_idx)\n",
    "        if 'spectral_bandwidth_2' in features_list:\n",
    "            spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(y+0.01, sr=sr)\n",
    "            feature_shapes.append(spectral_bandwidth_2.shape)\n",
    "            #print(\"spectral_bandwidth_2:\")\n",
    "            #print(spectral_bandwidth_2.shape)\n",
    "            columns.append('spectral_bandwidth_2')\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+spectral_bandwidth_2.shape[0]] = spectral_bandwidth_2.T[0:spectral_bandwidth_2.shape[1], :]\n",
    "                start_idx += spectral_bandwidth_2.shape[0]\n",
    "                #print(\"spectral_bandwidth_2 start_idx updated to: \", start_idx)\n",
    "        if 'spectral_bandwidth_3' in features_list:\n",
    "            spectral_bandwidth_3 = librosa.feature.spectral_bandwidth(y+0.01, sr=sr, p=3)\n",
    "            feature_shapes.append(spectral_bandwidth_3.shape)\n",
    "            #print(\"spectral_bandwidth_3:\")\n",
    "            #print(spectral_bandwidth_3.shape)\n",
    "            columns.append('spectral_bandwidth_3')\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+spectral_bandwidth_3.shape[0]] = spectral_bandwidth_3.T[0:spectral_bandwidth_3.shape[1], :]\n",
    "                start_idx += spectral_bandwidth_3.shape[0]\n",
    "                #print(\"spectral_bandwidth_3 start_idx updated to: \", start_idx)\n",
    "        if 'spectral_bandwidth_4' in features_list:\n",
    "            spectral_bandwidth_4 = librosa.feature.spectral_bandwidth(y+0.01, sr=sr, p=4)\n",
    "            feature_shapes.append(spectral_bandwidth_4.shape)\n",
    "            #print(\"spectral_bandwidth_4:\")\n",
    "            #print(spectral_bandwidth_4.shape)\n",
    "            columns.append('spectral_bandwidth_4')\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+spectral_bandwidth_4.shape[0]] = spectral_bandwidth_4.T[0:spectral_bandwidth_4.shape[1], :]\n",
    "                start_idx += spectral_bandwidth_4.shape[0]\n",
    "                #print(\"spectral_bandwidth_4 start_idx updated to: \", start_idx)\n",
    "        if 'spectral_contrast' in features_list:\n",
    "            spectral_contrast = librosa.feature.spectral_contrast(\n",
    "                y=y, sr=sr, hop_length=hop_length\n",
    "            )\n",
    "            feature_shapes.append(spectral_contrast.shape)\n",
    "            #print(\"spectral_contrast:\")\n",
    "            #print(spectral_contrast.shape)\n",
    "            #print(spectral_contrast)\n",
    "            #print(spectral_contrast.T)\n",
    "            for i in range(1, spectral_contrast.shape[0]+1):\n",
    "                columns.append('spcontr{}'.format(i))\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+spectral_contrast.shape[0]] = spectral_contrast.T[0:spectral_contrast.shape[1], :]\n",
    "                start_idx += spectral_contrast.shape[0]\n",
    "                #print(\"spectral_contrast start_idx updated to: \", start_idx)\n",
    "        if 'spect' in features_list:\n",
    "            spect = librosa.feature.melspectrogram(y=y, sr=sr,n_fft=n_fft, hop_length=hop_length)\n",
    "            spect = librosa.power_to_db(spect, ref=np.max)\n",
    "            feature_shapes.append(spect.shape)\n",
    "            #print(\"spect:\")\n",
    "            #print(spect.shape)\n",
    "            for i in range(1, spect.shape[0]+1):\n",
    "                columns.append('spect{}'.format(i))\n",
    "            if shp_0 is not None:\n",
    "                data[:, start_idx:start_idx+spect.shape[0]] = spect.T[0:spect.shape[1], :]\n",
    "                start_idx += spect.shape[0]\n",
    "                #print(\"spect start_idx updated to: \", start_idx)\n",
    "\n",
    "        new_shp_0 = shp_0\n",
    "        new_shp_1 = shp_1\n",
    "        if shp_0 is None:\n",
    "            #print(feature_shapes)\n",
    "            new_shp_0 = 0\n",
    "            for i, shp in enumerate(feature_shapes):\n",
    "                if i == 0:\n",
    "                    prev_shp_1 = shp[1]\n",
    "                else:\n",
    "                    if shp[1] != prev_shp_1:\n",
    "                        print(\"ERROR: shape[1] are different: {} != {}\".format(shp[1], prev_shp_1))\n",
    "                print(\"shp[0] :\", shp[0])\n",
    "                new_shp_0 += shp[0]\n",
    "            new_shp_1 = prev_shp_1\n",
    "            print(\"new_shp_0 :\", new_shp_0)\n",
    "            print(\"new_shp_1 :\", new_shp_1)\n",
    "\n",
    "        #print(\"duration :\", duration)\n",
    "\n",
    "    except:\n",
    "            print(\"Couldn't process, skipping: \", file_name)\n",
    "\n",
    "    return columns, data, feature_shapes, new_shp_0, new_shp_1\n",
    "\n",
    "# Suras: Update 'Set' column with test/train/val in df\n",
    "def assign_set_sura(row):\n",
    "    \"\"\" Mark Suras for Test/Train/Validation (uses row.Sura column). Requires Train_/Val_/Test_Suras lists to be defined prior to calling.\n",
    "\n",
    "       :param row: DataFrame row\n",
    "       :type row: DataFrame row\n",
    "       :return: None\n",
    "       :rtype: None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    train = Train_Suras\n",
    "    val   = Val_Suras\n",
    "    test  = Test_Suras\n",
    "    if row.Sura in val:\n",
    "        return \"validation\"\n",
    "    elif row.Sura in test:\n",
    "        return \"test\"\n",
    "    else:\n",
    "        return \"train\"\n",
    "\n",
    "# Ayas: Update 'Set' column with test/train/val in df\n",
    "def assign_set_aya(row):\n",
    "    \"\"\" Mark Ayas for Test/Train/Validation (uses row.AyaInQuran column). Requires Train_/Val_/Test_Ayas lists to be defined prior to calling.\n",
    "\n",
    "       :param row: DataFrame row\n",
    "       :type row: DataFrame row\n",
    "       :return: None\n",
    "       :rtype: None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    train = Train_Ayas\n",
    "    val   = Val_Ayas\n",
    "    test  = Test_Ayas\n",
    "    if row.AyaInQuran in val:\n",
    "        return \"validation\"\n",
    "    elif row.AyaInQuran in test:\n",
    "        return \"test\"\n",
    "    else:\n",
    "        return \"train\"\n",
    "\n",
    "# Ayas: Update 'Set' column with test/train/val in df\n",
    "def assign_set_filename(row):\n",
    "    \"\"\" Mark Ayas for Test/Train/Validation (uses row.FileName column). Requires Train_/Val_/Test_Ayas lists to be defined prior to calling.\n",
    "\n",
    "       :param row: DataFrame row\n",
    "       :type row: DataFrame row\n",
    "       :return: None\n",
    "       :rtype: None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    train = Train_Ayas\n",
    "    val   = Val_Ayas\n",
    "    test  = Test_Ayas\n",
    "    if row.FileName in val:\n",
    "        return \"validation\"\n",
    "    elif row.FileName in test:\n",
    "        return \"test\"\n",
    "    else:\n",
    "        return \"train\"\n",
    "\n",
    "def gen_audio_data(df, shp0, shp1, normalization=True):\n",
    "    \"\"\" Extract audio features for the given df which is a Train/Val/Test subset of the main df.\n",
    "\n",
    "       :param df: DataFrame\n",
    "       :type df: DataFrame\n",
    "       :param shp_0: Initialize the return data NumPy array with this shape\n",
    "       :type shp_0: int\n",
    "       :param shp_1: Initialize the return data NumPy array with this shape\n",
    "       :type shp_1: int\n",
    "       :param normalization: Normalize the MFCC data. Only works for the MFCC feature\n",
    "       :type normalization: bool\n",
    "       :return: X_arr, reciters_arr\n",
    "       :rtype: NumPy arr, NumPy arr\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"shp0 shp1 = \", shp0, shp1)\n",
    "    X_arr = np.empty((0, shp1, shp0))\n",
    "    print(\"X_arr initialized to :\", X_arr.shape)\n",
    "    reciters_arr = np.empty((0, len(list(le.classes_))))\n",
    "    print(\"reciters_arr initialized to :\", reciters_arr.shape)\n",
    "    print(\"normalization :\", normalization)\n",
    "\n",
    "    cnt = 0\n",
    "    for index, row in df.iterrows():\n",
    "        cnt += 1\n",
    "        ReciterName = row['ReciterName']\n",
    "        FileName = row['FileName']\n",
    "        # Get audio features\n",
    "        columns, data, feature_shapes, new_shp_0, new_shp_1 = extract_audio_features(\n",
    "                reciter=ReciterName, mp3_file=FileName, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, \n",
    "                hop_length=hop_length, pad_duration=pad_duration, read_duration=read_duration, \n",
    "                features_list=features_list, shp_0=shp0, shp_1=shp1, normalization=normalization)\n",
    "        if columns == None and data == None and feature_shapes == None:\n",
    "            # Skips in case of errors\n",
    "            continue\n",
    "\n",
    "        X_arr = np.append(X_arr, [data], axis=0)\n",
    "                            \n",
    "        reciters_list = [0 for i in range(0, len(list(le.classes_)))]\n",
    "        reciters_index = list(le.transform([ReciterName]))[0]\n",
    "        reciters_list[reciters_index] = 1\n",
    "        reciters_arr = np.append(reciters_arr, [reciters_list], axis=0)\n",
    "            \n",
    "        if cnt % 100 == 0:\n",
    "            print(\"Processed \", cnt)\n",
    "        #if cnt == 10:\n",
    "        #    break\n",
    "\n",
    "    return X_arr, reciters_arr\n",
    "\n",
    "def filter_duration(row):\n",
    "    \"\"\" Finds the same FileName for all the selected_reciters (uses row.FileName/row.ReciterName columns). Uses selected_reciters variable to look for the recieter, so it needs to be defined.\n",
    "\n",
    "       :param row: DataFrame row\n",
    "       :type row: DataFrame row\n",
    "       :return: 'Yes' or 'NaN'\n",
    "       :rtype: str\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    my_df = df_tmp\n",
    "    FileName = row.FileName\n",
    "    #print(\"FileName =\", FileName)\n",
    "    not_found = False\n",
    "    for rec in selected_reciters:\n",
    "        #print(\"  rec =\", rec)\n",
    "        if ((my_df['ReciterName'] == rec) & (my_df['FileName'] == FileName)).any():\n",
    "            pass\n",
    "        else:\n",
    "            not_found = True\n",
    "            #print(\"not_found =\", not_found)\n",
    "            break\n",
    "    \n",
    "    if not_found == True:\n",
    "        return 'NaN'\n",
    "    else:\n",
    "        return 'Yes'\n",
    "\n",
    "print(\"helpers.py LOADED!\")\n",
    "# End of helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dir is:  D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# imports\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import pathlib\n",
    "import xml.etree.ElementTree as ET\n",
    "import zipfile\n",
    "import shutil\n",
    "import librosa\n",
    "import math\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "import audioread\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import ExcelWriter\n",
    "from pydub.utils import mediainfo\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Current dir is: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Default Constants\n",
    "# Directory where MP3 files have been downloaded\n",
    "zip_data_dir   = '../DownloadedReciters'\n",
    "# Name of ZIP file for each reciter\n",
    "zip_file_name  = '000_versebyverse.zip'\n",
    "# Directory where processed data & other generated data will be stored\n",
    "data_dir       = '../data'\n",
    "audio_data_dir = os.path.join(os.getcwd(), data_dir, \"audio\")\n",
    "quran_meta_xml = os.path.join(os.getcwd(), 'Qurandata', \"quran-data.xml\")\n",
    "# Max/Min number of Sura/Aya with first as index 1\n",
    "SuraIndexMIN   = 1\n",
    "SuraIndexMAX   = 114\n",
    "AyaIndexMIN    = 0\n",
    "AyaIndexMAX    = 6236\n",
    "\n",
    "# Suppress this warning from librosa:\n",
    "# UserWarning: PySoundFile failed. Trying audioread instead.\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE in 0.014 sec\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>AyaInQuran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001004</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001006</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>001007</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002001</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>002002</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002003</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label  AyaInQuran\n",
       "0  001001           0\n",
       "1  001002           1\n",
       "2  001003           2\n",
       "3  001004           3\n",
       "4  001005           4\n",
       "5  001006           5\n",
       "6  001007           6\n",
       "7  002001           7\n",
       "8  002002           8\n",
       "9  002003           9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a lookup table between Mp3 filename and AyaInQuran\n",
    "t0 = time.time()\n",
    "labels_list, ayainq_list = qsura_ayat_to_labels(ayaFrom=AyaIndexMIN, \n",
    "                                                ayaTo=AyaIndexMAX)\n",
    "lbl_aya_df = pd.DataFrame(list(zip(labels_list, ayainq_list)), \n",
    "               columns=['Label', 'AyaInQuran']) \n",
    "\n",
    "lbl_aya_dict = dict(zip(labels_list, ayainq_list))\n",
    "print(\"DONE in {:0.3} sec\\n\".format(time.time() - t0))\n",
    "\n",
    "lbl_aya_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reciter name                   Data Size  Files    MP3 Files\n",
      "============                   =========  =====    =========\n",
      "AbdulBasit                        864 MB   6255         6253\n",
      "AbdullahBasfar                    435 MB   6239         6236\n",
      "AbdulSamad                       1643 MB   6240         6238\n",
      "AbdurrahmaanAs-Sudais             584 MB   6351         6349\n",
      "AbuBakrAsh-Shaatree               729 MB   6356         6353\n",
      "Ajami                            1436 MB   6354         6350\n",
      "Alafasy                           825 MB   6352         6350\n",
      "AliJaber                          701 MB   6354         6351\n",
      "FaresAbbad                        594 MB   6357         6353\n",
      "Ghamadi                           426 MB   6351         6349\n",
      "HaniRifai                         702 MB   6239         6237\n",
      "Karim Mansoori-Iran              1015 MB   6352         6348\n",
      "KhalefaAl-Tunaiji                 757 MB   6238         6236\n",
      "MaherAlMuaiqly                    586 MB   6350         6348\n",
      "MinshawyMujawwad                 1650 MB   6351         6349\n",
      "MohammadalTablaway                822 MB   6352         6350\n",
      "MuhammadAyyoub                    891 MB   6353         6351\n",
      "MuhammadJibreel                   724 MB   6352         6350\n",
      "Parhizgar                         572 MB   6242         6240\n",
      "SaoodbinIbraaheemAsh-Shuraym      510 MB   6360         6358\n",
      "DONE in 1.14 sec\n",
      "\n",
      "\n",
      "Downloaded Reciter name list :\n",
      " ['AbdulBasit', 'AbdullahBasfar', 'AbdulSamad', 'AbdurrahmaanAs-Sudais', 'AbuBakrAsh-Shaatree', 'Ajami', 'Alafasy', 'AliJaber', 'FaresAbbad', 'Ghamadi', 'HaniRifai', 'Karim Mansoori-Iran', 'KhalefaAl-Tunaiji', 'MaherAlMuaiqly', 'MinshawyMujawwad', 'MohammadalTablaway', 'MuhammadAyyoub', 'MuhammadJibreel', 'Parhizgar', 'SaoodbinIbraaheemAsh-Shuraym']\n"
     ]
    }
   ],
   "source": [
    "# Report stats on all downloaded data\n",
    "t0 = time.time()\n",
    "reciter_names = report_stats_zip_data(zip_data_dir=zip_data_dir, zip_file_name=zip_file_name)\n",
    "print(\"DONE in {:0.3} sec\\n\".format(time.time() - t0))\n",
    "\n",
    "print(\"\\nDownloaded Reciter name list :\\n\", reciter_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reciter selection\n",
    "The following 5 reciters were selected:\n",
    "- Ghamadi\n",
    "- Abdurrahmaan As-Sudais -> AbdurrahmaanAs-Sudais\n",
    "- Ahmed Ibn Ali Al Ajamy -> Ajami\n",
    "- Alafasy\n",
    "- Fares Abbad -> Fares Abbad\n",
    "\n",
    "Select 3000 Ayas. 60% Ayas will be used for training, 20% for validation, and 20% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected reciter:  ['Ghamadi', 'AbdurrahmaanAs-Sudais', 'Ajami', 'Alafasy', 'FaresAbbad']\n",
      "Selected Suras/Ayas: \n",
      "      suraFrom:  None\n",
      "        suraTo:  None\n",
      "       ayaFrom:  0\n",
      "         ayaTo:  2999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of reciters we are interested in\n",
    "selected_reciters = ['Ghamadi', 'AbdurrahmaanAs-Sudais', 'Ajami', 'Alafasy', 'FaresAbbad']\n",
    "print(\"Selected reciter: \", selected_reciters)\n",
    "\n",
    "# List of Sura/Ayas we are interested in\n",
    "suraFrom = None\n",
    "suraTo   = None\n",
    "ayaFrom  = AyaIndexMIN\n",
    "ayaTo    = 2999\n",
    "\n",
    "print(\"Selected Suras/Ayas: \")\n",
    "print(\"      suraFrom: \", suraFrom)\n",
    "print(\"        suraTo: \", suraTo)\n",
    "print(\"       ayaFrom: \", ayaFrom)\n",
    "print(\"         ayaTo: \", ayaTo)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists, deleting : D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\\../data\\audio\n",
      "Creating directory : D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\\../data\\audio\n",
      "Found reciter:  AbdurrahmaanAs-Sudais\n",
      "Creating directory : D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\\../data\\audio\\AbdurrahmaanAs-Sudais\n",
      "AbdurrahmaanAs-Sudais             584 MB   6351         6349\n",
      "3000 files extracted\n",
      "Found reciter:  Ajami\n",
      "Creating directory : D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\\../data\\audio\\Ajami\n",
      "Ajami                            1436 MB   6354         6350\n",
      "3000 files extracted\n",
      "Found reciter:  Alafasy\n",
      "Creating directory : D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\\../data\\audio\\Alafasy\n",
      "Alafasy                           825 MB   6352         6350\n",
      "3000 files extracted\n",
      "Found reciter:  FaresAbbad\n",
      "Creating directory : D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\\../data\\audio\\FaresAbbad\n",
      "FaresAbbad                        594 MB   6357         6353\n",
      "3000 files extracted\n",
      "Found reciter:  Ghamadi\n",
      "Creating directory : D:\\Khurram\\Udacity\\Udacity_ML_Course\\MKC\\P3_Capstone\\identify_reciter\\../data\\audio\\Ghamadi\n",
      "Ghamadi                           426 MB   6351         6349\n",
      "3000 files extracted\n",
      "\n",
      "DONE in 1.7e+02 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not pathlib.Path(data_dir).exists():\n",
    "    print(\"Directory doesn't exist ...\")\n",
    "    audio_data_initialize(dir_name=data_dir)\n",
    "\n",
    "# Start from a clean data directory\n",
    "audio_data_initialize(dir_name=audio_data_dir)\n",
    "\n",
    "# Populate the data directory with MP3 files for the reciters\n",
    "t0 = time.time()\n",
    "populate_audio_files(zip_data_dir=zip_data_dir, zip_file_name=zip_file_name, \n",
    "        audio_data_dir=audio_data_dir, reciters=selected_reciters, suraFrom=suraFrom, suraTo=suraTo,\n",
    "        ayaFrom=ayaFrom, ayaTo=ayaTo)\n",
    "print(\"DONE in {:0.3} sec\\n\".format(time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reciter name/MP3 File          Data Size  MP3s kbps Ch Mono/S Duration(sec)\n",
      "============================== =========  ==== ==== == ====== =============\n",
      "AbdurrahmaanAs-Sudais          356372 KB  3000\n",
      "Ajami                          871152 KB  3000\n",
      "Alafasy                        507975 KB  3000\n",
      "FaresAbbad                     357083 KB  3000\n",
      "Ghamadi                        264714 KB  3000\n",
      "DONE in 4.25e+03 sec\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Report stats on all the extracted MP3 files and get the details in a DataFrame\n",
    "t0 = time.time()\n",
    "df = report_stats_audio_data(data_dir=audio_data_dir)\n",
    "print(\"DONE in {:0.3} sec\\n\".format(time.time() - t0))\n",
    "\n",
    "print(\"\\n\\n\\nDONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the DataFrame df with all MP3 extracted info for future\n",
    "Save the DataFrame information in an Excel file. This helps extract the data & use Librosa to read MP3 file information only one time (both are slow processes to run). Once all the data is in the DataFrame \"df\", we can do remainder of the data preparation by using the df and updating it later as necessary (e.g. to mark ayas for train/val/test, etc.)\n",
    "\n",
    "**Note**: If you are executing this Notebook for the **first** time then save to Excel file by executing the cell below. **Skip** the below cell for later run, otherwise it will save the current df in memory which may lead to undesired results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir =  ../data\n"
     ]
    }
   ],
   "source": [
    "# SKIP IF DONE EARLIER!!!\n",
    "# Save the df \n",
    "from pandas import ExcelWriter\n",
    "print(\"data_dir = \", data_dir)\n",
    "my_excel_fileA = os.path.join(data_dir, 'pd_df_1.xlsx')\n",
    "writer = ExcelWriter(my_excel_fileA)\n",
    "df.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir =  data3\n"
     ]
    }
   ],
   "source": [
    "# SKIP IF RUNNING THIS NOTEBOOK FOR THE FIRST TIME!!!\n",
    "# Read info saved earlier to save time\n",
    "print(\"data_dir = \", data_dir)\n",
    "my_excel_fileA = os.path.join(data_dir, 'pd_df_1.xlsx')\n",
    "# Read Excel file\n",
    "df = pd.read_excel(my_excel_fileA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReciterName</th>\n",
       "      <th>FileName</th>\n",
       "      <th>DataSizeKB</th>\n",
       "      <th>BitRate</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Mono/Stereo</th>\n",
       "      <th>Duration</th>\n",
       "      <th>FileNoExt</th>\n",
       "      <th>Sura</th>\n",
       "      <th>Aya</th>\n",
       "      <th>AyaInQuran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AbdurrahmaanAs-Sudais</td>\n",
       "      <td>001001.mp3</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>3.003719</td>\n",
       "      <td>001001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AbdurrahmaanAs-Sudais</td>\n",
       "      <td>001002.mp3</td>\n",
       "      <td>35</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>4.414331</td>\n",
       "      <td>001002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AbdurrahmaanAs-Sudais</td>\n",
       "      <td>001003.mp3</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>3.029841</td>\n",
       "      <td>001003</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AbdurrahmaanAs-Sudais</td>\n",
       "      <td>001004.mp3</td>\n",
       "      <td>27</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>3.369433</td>\n",
       "      <td>001004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AbdurrahmaanAs-Sudais</td>\n",
       "      <td>001005.mp3</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>4.858413</td>\n",
       "      <td>001005</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ReciterName    FileName  DataSizeKB  BitRate  Channels  \\\n",
       "0  AbdurrahmaanAs-Sudais  001001.mp3          24       64         2   \n",
       "1  AbdurrahmaanAs-Sudais  001002.mp3          35       64         2   \n",
       "2  AbdurrahmaanAs-Sudais  001003.mp3          24       64         2   \n",
       "3  AbdurrahmaanAs-Sudais  001004.mp3          27       64         2   \n",
       "4  AbdurrahmaanAs-Sudais  001005.mp3          38       64         2   \n",
       "\n",
       "  Mono/Stereo  Duration FileNoExt  Sura  Aya  AyaInQuran  \n",
       "0      stereo  3.003719    001001     1    1           0  \n",
       "1      stereo  4.414331    001002     1    2           1  \n",
       "2      stereo  3.029841    001003     1    3           2  \n",
       "3      stereo  3.369433    001004     1    4           3  \n",
       "4      stereo  4.858413    001005     1    5           4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick look at the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick look at the DataFrame shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len =  3000\n",
      "test_val_ayas =  600\n",
      "        val_start_idx =  2399\n",
      "       test_start_idx =  1799\n"
     ]
    }
   ],
   "source": [
    "# Mark ayas for each reciter for training/test/validation\n",
    "\n",
    "# Work with a copy of the df.\n",
    "dfD = df.copy()\n",
    "\n",
    "# Add a new column to see if Ayas are Common among all reciters\n",
    "# This was needed when I was ignoring some durations, and wanted\n",
    "# to make sure I only keep the common Ayas between reciters. \n",
    "# It's no longer needed but keeping it just-in-case.\n",
    "newcol = 'Common'\n",
    "dfD[newcol] = 'Yes'\n",
    "df_tmp = dfD\n",
    "\n",
    "# Save the df with the new column\n",
    "my_out_file = os.path.join(data_dir, 'pd_df_2.xlsx')\n",
    "writer = ExcelWriter(my_out_file)\n",
    "df_tmp.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n",
    "\n",
    "# Only select the common ayas between all reciters\n",
    "df_tmp = df_tmp[df_tmp[newcol] == 'Yes']\n",
    "\n",
    "# Get all the available ayas in the df & create index boundaries for \n",
    "# Train/Val/Test\n",
    "FileNames = list(df_tmp['FileName'].unique())\n",
    "print(\"len = \", len(FileNames))\n",
    "tot_ayas = len(FileNames)\n",
    "test_val_ayas = math.ceil(0.2 * tot_ayas)\n",
    "print(\"test_val_ayas = \", test_val_ayas)\n",
    "\n",
    "val_start_idx  = tot_ayas - 1 - test_val_ayas\n",
    "test_start_idx = val_start_idx - test_val_ayas\n",
    "print(\"        val_start_idx = \", val_start_idx)\n",
    "print(\"       test_start_idx = \", test_start_idx)\n",
    "Val_Ayas   = FileNames[val_start_idx+1:tot_ayas+1]\n",
    "Test_Ayas  = FileNames[test_start_idx+1:val_start_idx+1]\n",
    "Train_Ayas = FileNames[0:test_start_idx+1]\n",
    "\n",
    "df_tmp['Set'] = df_tmp.apply(assign_set_filename, axis=1)\n",
    "\n",
    "# Save the df after updating Train/Val/Test info.\n",
    "my_out_file = os.path.join(data_dir, 'pd_df_3.xlsx')\n",
    "writer = ExcelWriter(my_out_file)\n",
    "df_tmp.to_excel(writer,'Sheet1',index=False)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test: Number of items = 600, StartIndex = 1800, EndIndex = 2399\n",
      "  Val: Number of items = 600, StartIndex = 2400, EndIndex = 2999\n",
      "Train: Number of items = 1800, StartIndex = 0, EndIndex = 1799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810,\n",
       "       1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821,\n",
       "       1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832,\n",
       "       1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843,\n",
       "       1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854,\n",
       "       1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865,\n",
       "       1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876,\n",
       "       1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887,\n",
       "       1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898,\n",
       "       1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909,\n",
       "       1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920,\n",
       "       1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931,\n",
       "       1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942,\n",
       "       1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953,\n",
       "       1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964,\n",
       "       1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975,\n",
       "       1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986,\n",
       "       1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997,\n",
       "       1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008,\n",
       "       2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019,\n",
       "       2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030,\n",
       "       2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041,\n",
       "       2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052,\n",
       "       2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063,\n",
       "       2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074,\n",
       "       2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085,\n",
       "       2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096,\n",
       "       2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107,\n",
       "       2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118,\n",
       "       2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129,\n",
       "       2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140,\n",
       "       2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151,\n",
       "       2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2160, 2161, 2162,\n",
       "       2163, 2164, 2165, 2166, 2167, 2168, 2169, 2170, 2171, 2172, 2173,\n",
       "       2174, 2175, 2176, 2177, 2178, 2179, 2180, 2181, 2182, 2183, 2184,\n",
       "       2185, 2186, 2187, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195,\n",
       "       2196, 2197, 2198, 2199, 2200, 2201, 2202, 2203, 2204, 2205, 2206,\n",
       "       2207, 2208, 2209, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217,\n",
       "       2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228,\n",
       "       2229, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239,\n",
       "       2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250,\n",
       "       2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2260, 2261,\n",
       "       2262, 2263, 2264, 2265, 2266, 2267, 2268, 2269, 2270, 2271, 2272,\n",
       "       2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2282, 2283,\n",
       "       2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294,\n",
       "       2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305,\n",
       "       2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316,\n",
       "       2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327,\n",
       "       2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338,\n",
       "       2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349,\n",
       "       2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360,\n",
       "       2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371,\n",
       "       2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382,\n",
       "       2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393,\n",
       "       2394, 2395, 2396, 2397, 2398, 2399], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410,\n",
       "       2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2421,\n",
       "       2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432,\n",
       "       2433, 2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2443,\n",
       "       2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454,\n",
       "       2455, 2456, 2457, 2458, 2459, 2460, 2461, 2462, 2463, 2464, 2465,\n",
       "       2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476,\n",
       "       2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487,\n",
       "       2488, 2489, 2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2498,\n",
       "       2499, 2500, 2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509,\n",
       "       2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517, 2518, 2519, 2520,\n",
       "       2521, 2522, 2523, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2531,\n",
       "       2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542,\n",
       "       2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2553,\n",
       "       2554, 2555, 2556, 2557, 2558, 2559, 2560, 2561, 2562, 2563, 2564,\n",
       "       2565, 2566, 2567, 2568, 2569, 2570, 2571, 2572, 2573, 2574, 2575,\n",
       "       2576, 2577, 2578, 2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586,\n",
       "       2587, 2588, 2589, 2590, 2591, 2592, 2593, 2594, 2595, 2596, 2597,\n",
       "       2598, 2599, 2600, 2601, 2602, 2603, 2604, 2605, 2606, 2607, 2608,\n",
       "       2609, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619,\n",
       "       2620, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2628, 2629, 2630,\n",
       "       2631, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641,\n",
       "       2642, 2643, 2644, 2645, 2646, 2647, 2648, 2649, 2650, 2651, 2652,\n",
       "       2653, 2654, 2655, 2656, 2657, 2658, 2659, 2660, 2661, 2662, 2663,\n",
       "       2664, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2672, 2673, 2674,\n",
       "       2675, 2676, 2677, 2678, 2679, 2680, 2681, 2682, 2683, 2684, 2685,\n",
       "       2686, 2687, 2688, 2689, 2690, 2691, 2692, 2693, 2694, 2695, 2696,\n",
       "       2697, 2698, 2699, 2700, 2701, 2702, 2703, 2704, 2705, 2706, 2707,\n",
       "       2708, 2709, 2710, 2711, 2712, 2713, 2714, 2715, 2716, 2717, 2718,\n",
       "       2719, 2720, 2721, 2722, 2723, 2724, 2725, 2726, 2727, 2728, 2729,\n",
       "       2730, 2731, 2732, 2733, 2734, 2735, 2736, 2737, 2738, 2739, 2740,\n",
       "       2741, 2742, 2743, 2744, 2745, 2746, 2747, 2748, 2749, 2750, 2751,\n",
       "       2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759, 2760, 2761, 2762,\n",
       "       2763, 2764, 2765, 2766, 2767, 2768, 2769, 2770, 2771, 2772, 2773,\n",
       "       2774, 2775, 2776, 2777, 2778, 2779, 2780, 2781, 2782, 2783, 2784,\n",
       "       2785, 2786, 2787, 2788, 2789, 2790, 2791, 2792, 2793, 2794, 2795,\n",
       "       2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 2804, 2805, 2806,\n",
       "       2807, 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2815, 2816, 2817,\n",
       "       2818, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2827, 2828,\n",
       "       2829, 2830, 2831, 2832, 2833, 2834, 2835, 2836, 2837, 2838, 2839,\n",
       "       2840, 2841, 2842, 2843, 2844, 2845, 2846, 2847, 2848, 2849, 2850,\n",
       "       2851, 2852, 2853, 2854, 2855, 2856, 2857, 2858, 2859, 2860, 2861,\n",
       "       2862, 2863, 2864, 2865, 2866, 2867, 2868, 2869, 2870, 2871, 2872,\n",
       "       2873, 2874, 2875, 2876, 2877, 2878, 2879, 2880, 2881, 2882, 2883,\n",
       "       2884, 2885, 2886, 2887, 2888, 2889, 2890, 2891, 2892, 2893, 2894,\n",
       "       2895, 2896, 2897, 2898, 2899, 2900, 2901, 2902, 2903, 2904, 2905,\n",
       "       2906, 2907, 2908, 2909, 2910, 2911, 2912, 2913, 2914, 2915, 2916,\n",
       "       2917, 2918, 2919, 2920, 2921, 2922, 2923, 2924, 2925, 2926, 2927,\n",
       "       2928, 2929, 2930, 2931, 2932, 2933, 2934, 2935, 2936, 2937, 2938,\n",
       "       2939, 2940, 2941, 2942, 2943, 2944, 2945, 2946, 2947, 2948, 2949,\n",
       "       2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2958, 2959, 2960,\n",
       "       2961, 2962, 2963, 2964, 2965, 2966, 2967, 2968, 2969, 2970, 2971,\n",
       "       2972, 2973, 2974, 2975, 2976, 2977, 2978, 2979, 2980, 2981, 2982,\n",
       "       2983, 2984, 2985, 2986, 2987, 2988, 2989, 2990, 2991, 2992, 2993,\n",
       "       2994, 2995, 2996, 2997, 2998, 2999], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 1797, 1798, 1799], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at Train/Val/Test Ayas to make sure no overlap\n",
    "lookcol = 'AyaInQuran'\n",
    "\n",
    "print(\" Test: Number of items = {}, StartIndex = {}, EndIndex = {}\".format(len(df_tmp[df_tmp['Set'] == \"test\"][lookcol].unique()), df_tmp[df_tmp['Set'] == \"test\"][lookcol].unique()[0], df_tmp[df_tmp['Set'] == \"test\"][lookcol].unique()[-1] ))\n",
    "print(\"  Val: Number of items = {}, StartIndex = {}, EndIndex = {}\".format(len(df_tmp[df_tmp['Set'] == \"validation\"][lookcol].unique()), df_tmp[df_tmp['Set'] == \"validation\"][lookcol].unique()[0], df_tmp[df_tmp['Set'] == \"validation\"][lookcol].unique()[-1] ))\n",
    "print(\"Train: Number of items = {}, StartIndex = {}, EndIndex = {}\".format(len(df_tmp[df_tmp['Set'] == \"train\"][lookcol].unique()), df_tmp[df_tmp['Set'] == \"train\"][lookcol].unique()[0], df_tmp[df_tmp['Set'] == \"train\"][lookcol].unique()[-1] ))\n",
    "\n",
    "# Check(s)\n",
    "display(df_tmp[df_tmp['Set'] == \"test\"][lookcol].unique())\n",
    "display(df_tmp[df_tmp['Set'] == \"validation\"][lookcol].unique())\n",
    "display(df_tmp[df_tmp['Set'] == \"train\"][lookcol].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReciterName</th>\n",
       "      <th>FileName</th>\n",
       "      <th>DataSizeKB</th>\n",
       "      <th>BitRate</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Mono/Stereo</th>\n",
       "      <th>Duration</th>\n",
       "      <th>FileNoExt</th>\n",
       "      <th>Sura</th>\n",
       "      <th>Aya</th>\n",
       "      <th>AyaInQuran</th>\n",
       "      <th>Common</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AbdurrahmaanAs-Sudais</td>\n",
       "      <td>001001.mp3</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>3.003719</td>\n",
       "      <td>001001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AbdurrahmaanAs-Sudais</td>\n",
       "      <td>001002.mp3</td>\n",
       "      <td>35</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>4.414331</td>\n",
       "      <td>001002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AbdurrahmaanAs-Sudais</td>\n",
       "      <td>001003.mp3</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>3.029841</td>\n",
       "      <td>001003</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AbdurrahmaanAs-Sudais</td>\n",
       "      <td>001004.mp3</td>\n",
       "      <td>27</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>3.369433</td>\n",
       "      <td>001004</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AbdurrahmaanAs-Sudais</td>\n",
       "      <td>001005.mp3</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>stereo</td>\n",
       "      <td>4.858413</td>\n",
       "      <td>001005</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ReciterName    FileName  DataSizeKB  BitRate  Channels  \\\n",
       "0  AbdurrahmaanAs-Sudais  001001.mp3          24       64         2   \n",
       "1  AbdurrahmaanAs-Sudais  001002.mp3          35       64         2   \n",
       "2  AbdurrahmaanAs-Sudais  001003.mp3          24       64         2   \n",
       "3  AbdurrahmaanAs-Sudais  001004.mp3          27       64         2   \n",
       "4  AbdurrahmaanAs-Sudais  001005.mp3          38       64         2   \n",
       "\n",
       "  Mono/Stereo  Duration FileNoExt  Sura  Aya  AyaInQuran Common    Set  \n",
       "0      stereo  3.003719    001001     1    1           0    Yes  train  \n",
       "1      stereo  4.414331    001002     1    2           1    Yes  train  \n",
       "2      stereo  3.029841    001003     1    3           2    Yes  train  \n",
       "3      stereo  3.369433    001004     1    4           3    Yes  train  \n",
       "4      stereo  4.858413    001005     1    5           4    Yes  train  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once satisfied with updated df_tmp, assign it back to df\n",
    "df = df_tmp.copy()\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  (3000, 13)\n",
      "validation:  (3000, 13)\n",
      "train:  (9000, 13)\n",
      "(3000, 13) (3000, 13) (9000, 13)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes\n",
    "print(\"test: \",df[df['Set'] == \"test\"].shape)\n",
    "print(\"validation: \",df[df['Set'] == \"validation\"].shape)\n",
    "print(\"train: \",df[df['Set'] == \"train\"].shape)\n",
    "\n",
    "df_test  = df[df['Set'] == \"test\"]\n",
    "df_valid = df[df['Set'] == \"validation\"]\n",
    "df_train = df[df['Set'] == \"train\"]\n",
    "\n",
    "print(df_test.shape, df_valid.shape, df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 5 ['AbdurrahmaanAs-Sudais', 'Ajami', 'Alafasy', 'FaresAbbad', 'Ghamadi']\n",
      "Classes: 5 [0, 1, 2, 3, 4]\n",
      "\n",
      "dict_reciter_to_label =  {'AbdurrahmaanAs-Sudais': 0, 'Ajami': 1, 'Alafasy': 2, 'FaresAbbad': 3, 'Ghamadi': 4}\n",
      "dict_label_to_reciter =  {0: 'AbdurrahmaanAs-Sudais', 1: 'Ajami', 2: 'Alafasy', 3: 'FaresAbbad', 4: 'Ghamadi'}\n"
     ]
    }
   ],
   "source": [
    "# Encoding for the reciters as lables\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['ReciterName'])\n",
    "\n",
    "print(\"Classes:\", len(list(le.classes_)), list(le.classes_))\n",
    "print(\"Classes:\", len(list(le.classes_)), list(le.transform(le.classes_)))\n",
    "print()\n",
    "#print(le.transform(df['ReciterName']))\n",
    "\n",
    "# Create a dictionary\n",
    "dict_reciter_to_label = dict(zip(list(le.classes_), list(le.transform(le.classes_))))\n",
    "print(\"dict_reciter_to_label = \", dict_reciter_to_label)\n",
    "dict_label_to_reciter = {v: k for k, v in dict_reciter_to_label.items()}\n",
    "print(\"dict_label_to_reciter = \", dict_label_to_reciter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(le.transform(['Alafasy']))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Audio Features\n",
    "I wanted to make sure I am able to explore & switch between different features easily so there are many audio features that have been coded in the helper function \"extract_audio_features\".\n",
    "\n",
    "From the data frame it is clear that the various MP3 files have different characteristics. Almost all of these need to be \"matched\" in order to get the correct data. Here is how this was acheived:\n",
    "- Bit rate (kbps)    - This didn't seem to make a difference, so nothing was done about this characteristic.\n",
    "- Sample rate (kHz)  - The sample rate needs to be the same across all audio files so features are comparable. Librosa can be given the sample rate as an input. The default is \"22050\". I left it at default so all the files will be re-sampled at this rate during the read operation.\n",
    "- Duration (seconds) - The duration needs to be the same across all audio files. Librosa by default reads the whole duration of the file. We can read a smaller duration but can't \"pad\" the duration during read. There were two options to deal with the varying durations of the audio files:\n",
    "     - Figure out min duration & only read the minimum duration.\n",
    "     - Figure out max duration & pad the duration after reading the MP3 file.\n",
    "     - Figure out an arbitrary number like 3 seconds. If this works then it's great at keeping the data size small!\n",
    "     \n",
    "     After experimenting with different durations starting from 30 seconds, I am finally choosing to go with the 3 sec duration.\n",
    "\n",
    "Other parameters (hop_length, etc.) are related to the Librosa and were made the same during feature extraction.\n",
    "\n",
    "One other thing to note is that in order to get same data array sizes from each audio file, we first run feature extraction on one audio file to get the \"shape\" of the data array. Then the data array is initilized and real feature extraction begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149.49877551020407\n",
      "150\n",
      "Max duration = 150 seconds\n",
      "0.9806575963718821\n",
      "1\n",
      "Min duration = 1 seconds\n"
     ]
    }
   ],
   "source": [
    "# Before audio features can be extracted, need to figure out the longest/shortest\n",
    "# duration and make all audio same duration\n",
    "duration_max = df['Duration'].max()\n",
    "print(duration_max)\n",
    "# Round it up\n",
    "new_max_duration = math.ceil(duration_max)\n",
    "print(new_max_duration)\n",
    "print(\"Max duration = {} seconds\".format(new_max_duration))\n",
    "\n",
    "duration_min = df['Duration'].min()\n",
    "print(duration_min)\n",
    "# Round it up\n",
    "new_min_duration = math.ceil(duration_min)\n",
    "print(new_min_duration)\n",
    "print(\"Min duration = {} seconds\".format(new_min_duration))\n",
    "# %load helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reciter       =  AbdurrahmaanAs-Sudais\n",
      "mp3_file      =  001001.mp3\n",
      "read_duration =  3\n",
      "pad_duration  =  3\n",
      "        shp_0 =  None\n",
      "        shp_1 =  None\n",
      "           sr =  22050\n",
      "        n_fft =  2048\n",
      "       n_mfcc =  13\n",
      "   hop_length =  512\n",
      "features_list =  ['spect']\n",
      "    savez_dir =  ../datamelspect\n",
      "Directory doesn't exist ...\n",
      "Creating directory : ../datamelspect\n"
     ]
    }
   ],
   "source": [
    "# Run feature extraction on one audio file to get the \"shape\" of the data array\n",
    "reciter = df.lookup([0], ['ReciterName'])[0]\n",
    "mp3_file = df.lookup([0], ['FileName'])[0]\n",
    "read_duration = pad_duration = 3\n",
    "shp_0 = shp_1 = None\n",
    "sr = 22050\n",
    "n_fft = 2048\n",
    "n_mfcc = 13\n",
    "hop_length = 512\n",
    "features_list = ['spect']\n",
    "savez_dir = '../datamelspect'\n",
    "\n",
    "print(\"reciter       = \", reciter)\n",
    "print(\"mp3_file      = \", mp3_file)\n",
    "print(\"read_duration = \", read_duration)\n",
    "print(\"pad_duration  = \", pad_duration)\n",
    "print(\"        shp_0 = \", shp_0)\n",
    "print(\"        shp_1 = \", shp_1)\n",
    "print(\"           sr = \", sr)\n",
    "print(\"        n_fft = \", n_fft)\n",
    "print(\"       n_mfcc = \", n_mfcc)\n",
    "print(\"   hop_length = \", hop_length)\n",
    "print(\"features_list = \", features_list)\n",
    "print(\"    savez_dir = \", savez_dir)\n",
    "\n",
    "if not pathlib.Path(savez_dir).exists():\n",
    "    print(\"Directory doesn't exist ...\")\n",
    "    audio_data_initialize(dir_name=savez_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shp[0] : 128\n",
      "new_shp_0 : 128\n",
      "new_shp_1 : 130\n",
      "reciter INIT:\n",
      "<class 'list'>\n",
      "shape 0/1 :\n",
      "128 130\n"
     ]
    }
   ],
   "source": [
    "columns, data, feature_shapes, new_shp_0, new_shp_1 = extract_audio_features(\n",
    "    reciter=reciter, mp3_file=mp3_file, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, \n",
    "    hop_length=hop_length, pad_duration=pad_duration, read_duration=read_duration, \n",
    "    features_list=features_list, shp_0=shp_0, shp_1=shp_1)\n",
    "print(\"reciter INIT:\")\n",
    "print(type(data))\n",
    "print(\"shape 0/1 :\")\n",
    "print(new_shp_0, new_shp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shp0 shp1 =  128 130\n",
      "X_arr initialized to : (0, 130, 128)\n",
      "reciters_arr initialized to : (0, 5)\n",
      "normalization : True\n",
      "Processed  100\n",
      "Processed  200\n",
      "Processed  300\n",
      "Processed  400\n",
      "Processed  500\n",
      "Processed  600\n",
      "Processed  700\n",
      "Processed  800\n",
      "Processed  900\n",
      "Processed  1000\n",
      "Processed  1100\n",
      "Processed  1200\n",
      "Processed  1300\n",
      "Processed  1400\n",
      "Processed  1500\n",
      "Processed  1600\n",
      "Processed  1700\n",
      "Processed  1800\n",
      "Processed  1900\n",
      "Processed  2000\n",
      "Processed  2100\n",
      "Processed  2200\n",
      "Processed  2300\n",
      "Processed  2400\n",
      "Processed  2500\n",
      "Processed  2600\n",
      "Processed  2700\n",
      "Processed  2800\n",
      "Processed  2900\n",
      "Processed  3000\n",
      "DONE in 9.46e+02 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "X_test, y_test = gen_audio_data(df_test, shp0=new_shp_0, shp1=new_shp_1)\n",
    "print(\"DONE in {:0.3} sec\\n\".format(time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 130, 128) (3000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(savez_dir, 'test_arr'), X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shp0 shp1 =  128 130\n",
      "X_arr initialized to : (0, 130, 128)\n",
      "reciters_arr initialized to : (0, 5)\n",
      "normalization : True\n",
      "Processed  100\n",
      "Processed  200\n",
      "Processed  300\n",
      "Processed  400\n",
      "Processed  500\n",
      "Processed  600\n",
      "Processed  700\n",
      "Processed  800\n",
      "Processed  900\n",
      "Processed  1000\n",
      "Processed  1100\n",
      "Processed  1200\n",
      "Processed  1300\n",
      "Processed  1400\n",
      "Processed  1500\n",
      "Processed  1600\n",
      "Processed  1700\n",
      "Processed  1800\n",
      "Processed  1900\n",
      "Processed  2000\n",
      "Processed  2100\n",
      "Processed  2200\n",
      "Processed  2300\n",
      "Processed  2400\n",
      "Processed  2500\n",
      "Processed  2600\n",
      "Processed  2700\n",
      "Processed  2800\n",
      "Processed  2900\n",
      "Processed  3000\n",
      "DONE in 9.43e+02 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "X_valid, y_valid = gen_audio_data(df_valid, shp0=new_shp_0, shp1=new_shp_1)\n",
    "print(\"DONE in {:0.3} sec\\n\".format(time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 130, 128) (3000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(savez_dir, 'valid_arr'), X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shp0 shp1 =  128 130\n",
      "X_arr initialized to : (0, 130, 128)\n",
      "reciters_arr initialized to : (0, 5)\n",
      "normalization : True\n",
      "Processed  100\n",
      "Processed  200\n",
      "Processed  300\n",
      "Processed  400\n",
      "Processed  500\n",
      "Processed  600\n",
      "Processed  700\n",
      "Processed  800\n",
      "Processed  900\n",
      "Processed  1000\n",
      "Processed  1100\n",
      "Processed  1200\n",
      "Processed  1300\n",
      "Processed  1400\n",
      "Processed  1500\n",
      "Processed  1600\n",
      "Processed  1700\n",
      "Processed  1800\n",
      "Processed  1900\n",
      "Processed  2000\n",
      "Processed  2100\n",
      "Processed  2200\n",
      "Processed  2300\n",
      "Processed  2400\n",
      "Processed  2500\n",
      "Processed  2600\n",
      "Processed  2700\n",
      "Processed  2800\n",
      "Processed  2900\n",
      "Processed  3000\n",
      "Processed  3100\n",
      "Processed  3200\n",
      "Processed  3300\n",
      "Processed  3400\n",
      "Processed  3500\n",
      "Processed  3600\n",
      "Processed  3700\n",
      "Processed  3800\n",
      "Processed  3900\n",
      "Processed  4000\n",
      "Processed  4100\n",
      "Processed  4200\n",
      "Processed  4300\n",
      "Processed  4400\n",
      "Processed  4500\n",
      "Processed  4600\n",
      "Processed  4700\n",
      "Processed  4800\n",
      "Processed  4900\n",
      "Processed  5000\n",
      "Processed  5100\n",
      "Processed  5200\n",
      "Processed  5300\n",
      "Processed  5400\n",
      "Processed  5500\n",
      "Processed  5600\n",
      "Processed  5700\n",
      "Processed  5800\n",
      "Processed  5900\n",
      "Processed  6000\n",
      "Processed  6100\n",
      "Processed  6200\n",
      "Processed  6300\n",
      "Processed  6400\n",
      "Processed  6500\n",
      "Processed  6600\n",
      "Processed  6700\n",
      "Processed  6800\n",
      "Processed  6900\n",
      "Processed  7000\n",
      "Processed  7100\n",
      "Processed  7200\n",
      "Processed  7300\n",
      "Processed  7400\n",
      "Processed  7500\n",
      "Processed  7600\n",
      "Processed  7700\n",
      "Processed  7800\n",
      "Processed  7900\n",
      "Processed  8000\n",
      "Processed  8100\n",
      "Processed  8200\n",
      "Processed  8300\n",
      "Processed  8400\n",
      "Processed  8500\n",
      "Processed  8600\n",
      "Processed  8700\n",
      "Processed  8800\n",
      "Processed  8900\n",
      "Processed  9000\n",
      "DONE in 5.22e+03 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "X_train, y_train = gen_audio_data(df_train, shp0=new_shp_0, shp1=new_shp_1)\n",
    "print(\"DONE in {:0.3} sec\\n\".format(time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 130, 128) (9000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(savez_dir, 'train_arr'), X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-08 1.0000008783668917 0.005410723282877886\n"
     ]
    }
   ],
   "source": [
    "# Convert the scale of training data\n",
    "X_train_raw = librosa.core.db_to_power(X_train, ref=1.0)\n",
    "print(np.amin(X_train_raw), np.amax(X_train_raw), np.mean(X_train_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.420680743952367 8.783665059016772e-07 -10.345927531676363\n"
     ]
    }
   ],
   "source": [
    "X_train_log = np.log(X_train_raw)\n",
    "print(np.amin(X_train_log), np.amax(X_train_log), np.mean(X_train_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_raw = librosa.core.db_to_power(X_valid, ref=1.0)\n",
    "X_valid_log = np.log(X_valid_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_same_way(arr1, arr2):\n",
    "    if len(arr1) != len(arr2):\n",
    "        print(\"ERROR: len(arr1) {} is different from len(arr2) {}, please fix and re-run!\"\n",
    "             .format(len(arr1), len(arr2)))\n",
    "        return arr1, arr2\n",
    "    perms = np.random.permutation(len(arr1))\n",
    "    return arr1[perms], arr2[perms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle_same_way(X_train_log, y_train)\n",
    "X_valid, y_valid = shuffle_same_way(X_valid_log, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes are:  (9000, 130, 128) (3000, 130, 128) (9000, 5) (3000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes are: \", X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(savez_dir, 'shuffled_train_log'), X_train, y_train)\n",
    "np.savez(os.path.join(savez_dir, 'shuffled_valid_log'), X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
